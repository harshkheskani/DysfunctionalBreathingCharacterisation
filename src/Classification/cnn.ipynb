{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df119221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import pytz\n",
    "import os\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96248335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 event files. Processing each one...\n",
      "  - Processing session: 26-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 08-05-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 05-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 10-05-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 24-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 25-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 16-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 11-05-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 04-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "\n",
      "----------------------------------------------------\n",
      "Data loading with PRECISE interval labeling complete.\n",
      "Final DataFrame shape: (2139235, 30)\n",
      "Final class distribution in raw data: \n",
      "Label\n",
      "0    0.988052\n",
      "1    0.011948\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load in Data\n",
    "EVENTS_FOLDER = '../../data/bishkek_csr/03_train_ready/event_exports' \n",
    "RESPECK_FOLDER = '../../data/bishkek_csr/03_train_ready/respeck'\n",
    "NASAL_FOLDER = '../../data/bishkek_csr/03_train_ready/nasal_files'\n",
    "FEATURES_FOLDER = '../../data/bishkek_csr/03_train_ready/respeck_features'\n",
    "# --- Define relevant events ---\n",
    "APNEA_EVENT_LABELS = [\n",
    "    'Obstructive Apnea'\n",
    "]\n",
    "\n",
    "all_sessions_df_list = []\n",
    "event_files = glob.glob(os.path.join(EVENTS_FOLDER, '*_event_export.csv'))\n",
    "\n",
    "if not event_files:\n",
    "    raise FileNotFoundError(f\"No event files found in '{EVENTS_FOLDER}'.\")\n",
    "\n",
    "print(f\"Found {len(event_files)} event files. Processing each one...\")\n",
    "\n",
    "for event_file_path in event_files:\n",
    "    # --- 1. Setup paths and IDs ---\n",
    "    base_name = os.path.basename(event_file_path)\n",
    "    session_id = base_name.split('_event_export.csv')[0]\n",
    "    respeck_file_path = os.path.join(RESPECK_FOLDER, f'{session_id}_respeck.csv')\n",
    "    nasal_file_path = os.path.join(NASAL_FOLDER, f'{session_id}_nasal.csv')\n",
    "    feature_file_path = os.path.join(FEATURES_FOLDER, f'{session_id}_respeck_features.csv')\n",
    "    \n",
    "    if not all(os.path.exists(p) for p in [respeck_file_path, nasal_file_path, feature_file_path]):\n",
    "        print(f\"  - WARNING: Skipping session '{session_id}'. A corresponding file is missing.\")\n",
    "        continue\n",
    "    print(f\"  - Processing session: {session_id}\")\n",
    "    \n",
    "    # --- 2. Load all data sources ---\n",
    "    df_events = pd.read_csv(event_file_path, decimal=',')\n",
    "    df_nasal = pd.read_csv(nasal_file_path)\n",
    "    df_respeck = pd.read_csv(respeck_file_path)\n",
    "    df_features = pd.read_csv(feature_file_path)\n",
    "\n",
    "    # --- 3. Standardize timestamp columns and types ---\n",
    "    df_events.rename(columns={'UnixTimestamp': 'timestamp_unix'}, inplace=True)\n",
    "    df_nasal.rename(columns={'UnixTimestamp': 'timestamp_unix'}, inplace=True, errors='ignore')\n",
    "    df_respeck.rename(columns={'alignedTimestamp': 'timestamp_unix'}, inplace=True)\n",
    "    \n",
    "    df_features['timestamp_unix'] = pd.to_datetime(df_features['startTimestamp'], format=\"mixed\")\n",
    "    df_features['timestamp_unix'] = df_features['timestamp_unix'].astype('int64') // 10**6\n",
    "\n",
    "    df_features['timestamp_unix_end'] = pd.to_datetime(df_features['endTimestamp'], format=\"mixed\")\n",
    "    df_features['timestamp_unix_end'] = df_features['timestamp_unix_end'].astype('int64') // 10**6\n",
    "    \n",
    "    for df_ in [df_events, df_nasal, df_respeck]:\n",
    "        df_['timestamp_unix'] = pd.to_numeric(df_['timestamp_unix'], errors='coerce')\n",
    "        df_.dropna(subset=['timestamp_unix'], inplace=True)\n",
    "        df_['timestamp_unix'] = df_['timestamp_unix'].astype('int64')\n",
    "\n",
    "    # --- 4. Calculate the true overlapping time range ---\n",
    "    start_time = max(df_nasal['timestamp_unix'].min(), df_respeck['timestamp_unix'].min())\n",
    "    end_time = min(df_nasal['timestamp_unix'].max(), df_respeck['timestamp_unix'].max())\n",
    "    \n",
    "    # --- 5. Trim Respeck data to the overlapping time range ---\n",
    "    df_respeck = df_respeck[(df_respeck['timestamp_unix'] >= start_time) & (df_respeck['timestamp_unix'] <= end_time)].copy()\n",
    "\n",
    "    if df_respeck.empty:\n",
    "        print(f\"  - WARNING: Skipping session '{session_id}'. No Respeck data in the overlapping range.\")\n",
    "        continue\n",
    "\n",
    "    print(\"  - Preparing and merging engineered features using Unix time intervals...\")\n",
    "    df_respeck = df_respeck.sort_values('timestamp_unix')\n",
    "    df_features = df_features.sort_values('timestamp_unix')\n",
    "\n",
    "    # Use merge_asof to find the correct feature window for each respeck data point\n",
    "    df_session_merged = pd.merge_asof(\n",
    "        df_respeck,\n",
    "        df_features,\n",
    "        on='timestamp_unix',\n",
    "        direction='backward' # Finds the last feature window that started <= the respeck timestamp\n",
    "    )\n",
    "\n",
    "    cols_to_drop = ['Unnamed: 0','startTimestamp', 'endTimestamp', 'timestamp_unix_end']\n",
    "    df_session_merged.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "    if df_session_merged.empty:\n",
    "        print(f\"  - WARNING: Skipping session '{session_id}'. No merge matches found.\")\n",
    "        continue\n",
    "        \n",
    "    # --- 6. **NEW: Precise Interval-Based Labeling using Duration** ---\n",
    "    print(f\"  - Applying precise interval-based labels...\")\n",
    "    \n",
    "    # ** Step 6a: Initialize the label column in the respeck data with 0 (Normal)\n",
    "    df_session_merged['Label'] = 0\n",
    "    \n",
    "    # ** Step 6b: Calculate event end times using the 'Duration' column\n",
    "    # The 'Duration' column has commas, which we handled with `decimal=','` at load time.\n",
    "    # Convert duration from seconds to milliseconds to match the Unix timestamps.\n",
    "    df_events['Duration_ms'] = (df_events['Duration'] * 1000).astype('int64')\n",
    "    df_events['end_time_unix'] = df_events['timestamp_unix'] + df_events['Duration_ms']\n",
    "    \n",
    "    # ** Step 6c: Filter for only the apnea/hypopnea events we want to label as '1'\n",
    "    df_apnea_events = df_events[df_events['Event'].isin(APNEA_EVENT_LABELS)].copy()\n",
    "\n",
    "    # ** Step 6d: Efficiently label the respeck data using event intervals\n",
    "    # This is much faster than looping. It checks which respeck timestamps fall\n",
    "    # within any of the [start, end] intervals of the apnea events.\n",
    "    for index, event in df_apnea_events.iterrows():\n",
    "        start_event = event['timestamp_unix']\n",
    "        end_event = event['end_time_unix']\n",
    "        # Set the 'Label' to 1 for all respeck rows within this event's time interval\n",
    "        df_session_merged.loc[df_session_merged['timestamp_unix'].between(start_event, end_event), 'Label'] = 1\n",
    "\n",
    "    # --- 7. Finalize session data ---\n",
    "    df_session_merged['SessionID'] = session_id\n",
    "    all_sessions_df_list.append(df_session_merged)\n",
    "\n",
    "# --- Combine all nights and perform final processing ---\n",
    "if not all_sessions_df_list:\n",
    "    raise ValueError(\"Processing failed. No data was loaded.\")\n",
    "\n",
    "df = pd.concat(all_sessions_df_list, ignore_index=True)\n",
    "\n",
    "\n",
    "df.to_csv('test.csv')\n",
    "print(\"\\n----------------------------------------------------\")\n",
    "print(\"Data loading with PRECISE interval labeling complete.\")\n",
    "print(f\"Final DataFrame shape: {df.shape}\")\n",
    "print(f\"Final class distribution in raw data: \\n{df['Label'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8ea2c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp_unix', 'timestamp', 'interpolatedPhoneTimestamp',\n",
      "       'respeckTimestamp', 'sequenceNumber', 'x', 'y', 'z', 'breathingSignal',\n",
      "       'breathingRate', 'activityLevel', 'activityType', 'type', 'area',\n",
      "       'extremas', 'meanActivityLevel', 'modeActivityType',\n",
      "       'peakRespiratoryFlow', 'duration', 'BR_md', 'BR_mean', 'BR_std',\n",
      "       'AL_md', 'AL_mean', 'AL_std', 'RRV', 'RRV3MA', 'breath_regularity',\n",
      "       'Label', 'SessionID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Windowing: Creating the time-series segments.\n",
    "print(df.columns)\n",
    "\n",
    "SAMPLING_RATE_HZ = 12.5\n",
    "WINDOW_DURATION_SEC = 30\n",
    "WINDOW_SIZE = int(WINDOW_DURATION_SEC * SAMPLING_RATE_HZ)\n",
    "\n",
    "# Step size for sliding window. An 80% overlap is a good start.\n",
    "OVERLAP_PERCENTAGE = 0.80\n",
    "STEP_SIZE = int(WINDOW_SIZE * (1 - OVERLAP_PERCENTAGE))\n",
    "\n",
    "# === Data Parameters ===\n",
    "FEATURE_COLUMNS = [\n",
    "    'breathingSignal', \n",
    "    'activityLevel',\n",
    "]\n",
    "LABEL_COLUMN = 'Label' \n",
    "SESSION_ID_COLUMN = 'SessionID'\n",
    "\n",
    "\n",
    "TEST_NIGHTS = 2\n",
    "TOTAL_NIGHTS = 9 \n",
    "TEST_SIZE = TEST_NIGHTS / TOTAL_NIGHTS\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e53241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for and imputing missing values (NaNs)...\n",
      "  - Found 4630 NaNs in 'breathingSignal'. Applying forward-fill and backward-fill.\n",
      "  - Found 2097749 NaNs in 'breathingRate'. Applying forward-fill and backward-fill.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qj/1f20_52j2yj49hjhy3ht9wzw0000gn/T/ipykernel_21794/370400962.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].ffill(inplace=True)\n",
      "/var/folders/qj/1f20_52j2yj49hjhy3ht9wzw0000gn/T/ipykernel_21794/370400962.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].bfill(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Found 2110 NaNs in 'type'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'area'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'extremas'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'meanActivityLevel'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'modeActivityType'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'peakRespiratoryFlow'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'duration'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'BR_md'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'BR_mean'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'BR_std'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'AL_md'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'AL_mean'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'AL_std'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'RRV'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'RRV3MA'. Applying forward-fill and backward-fill.\n",
      "  - Found 2110 NaNs in 'breath_regularity'. Applying forward-fill and backward-fill.\n",
      "\n",
      "Imputation complete. No NaNs remain in feature columns.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChecking for and imputing missing values (NaNs)...\")\n",
    "for col in df:\n",
    "    if col in df.columns:\n",
    "        nan_count = df[col].isnull().sum()\n",
    "        if nan_count > 0:\n",
    "            print(f\"  - Found {nan_count} NaNs in '{col}'. Applying forward-fill and backward-fill.\")\n",
    "            \n",
    "            # Step 1: Forward-fill handles all NaNs except leading ones.\n",
    "            df[col].ffill(inplace=True) \n",
    "            \n",
    "            # Step 2: Backward-fill handles any remaining NaNs at the beginning of the file.\n",
    "            df[col].bfill(inplace=True) \n",
    "\n",
    "# Add a final check to ensure everything is clean\n",
    "final_nan_count = df[FEATURE_COLUMNS].isnull().sum().sum()\n",
    "if final_nan_count > 0:\n",
    "    print(f\"\\nWARNING: {final_nan_count} NaNs still remain in feature columns after imputation. Please investigate.\")\n",
    "else:\n",
    "    print(\"\\nImputation complete. No NaNs remain in feature columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ed1b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the windowing process...\n",
      "\n",
      "Data windowing complete.\n",
      "----------------------------------------------------\n",
      "Shape of X (features): (28868, 375, 2) -> (Num_Windows, Window_Size, Num_Features)\n",
      "Shape of y (labels):   (28868,)\n",
      "Shape of groups (IDs): (28868,)\n",
      "Final class distribution across all windows: Counter({np.int64(0): 27958, np.int64(1): 910}) (0=Normal, 1=Apnea)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "groups = [] \n",
    "\n",
    "print(\"Starting the windowing process...\")\n",
    "\n",
    "# --- 3. Loop through each session (night) to create windows ---\n",
    "# We group by SessionID to ensure windows do not cross over between nights.\n",
    "for session_id, session_df in df.groupby(SESSION_ID_COLUMN):\n",
    "    for i in range(0, len(session_df) - WINDOW_SIZE, STEP_SIZE):\n",
    "        \n",
    "        window_df = session_df.iloc[i : i + WINDOW_SIZE]\n",
    "        \n",
    "        features = window_df[FEATURE_COLUMNS].values\n",
    "        \n",
    "        # --- CORRECTED LABELING LOGIC ---\n",
    "        # The 'Label' column already contains 0s and 1s.\n",
    "        # If the sum of labels in the window is > 0, it means there's at least one '1' (Apnea).\n",
    "        if window_df[LABEL_COLUMN].sum() > 0:\n",
    "            label = 1 # Apnea\n",
    "        else:\n",
    "            label = 0 # Normal\n",
    "        # ------------------------------------\n",
    "            \n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "        groups.append(session_id)\n",
    "\n",
    "# --- 4. Convert the lists into efficient NumPy arrays ---\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "groups = np.asarray(groups)\n",
    "\n",
    "# --- 5. Print a summary of the results ---\n",
    "print(\"\\nData windowing complete.\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(f\"Shape of X (features): {X.shape} -> (Num_Windows, Window_Size, Num_Features)\")\n",
    "print(f\"Shape of y (labels):   {y.shape}\")\n",
    "print(f\"Shape of groups (IDs): {groups.shape}\")\n",
    "print(f\"Final class distribution across all windows: {Counter(y)} (0=Normal, 1=Apnea)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475c0f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 unique sessions (nights) in the dataset: ['04-04-2025' '05-04-2025' '08-05-2025' '10-05-2025' '11-05-2025'\n",
      " '16-04-2025' '24-04-2025' '25-04-2025' '26-04-2025']\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "  - Sessions assigned to TRAINING set: ['16-04-2025' '04-04-2025' '26-04-2025' '08-05-2025' '11-05-2025'\n",
      " '10-05-2025' '24-04-2025']\n",
      "  - Sessions assigned to TESTING set:  ['25-04-2025' '05-04-2025']\n",
      "\n",
      "Train-test split complete.\n",
      "----------------------------------------------------\n",
      "Total windows in training set:   21374\n",
      "Total windows in testing set:    7494\n",
      "Shape of X_train:                (21374, 375, 2)\n",
      "Shape of X_test:                 (7494, 375, 2)\n",
      "Training set class distribution: Counter({np.int64(0): 20839, np.int64(1): 535}) (0=Normal, 1=Apnea)\n",
      "Testing set class distribution:  Counter({np.int64(0): 7119, np.int64(1): 375}) (0=Normal, 1=Apnea)\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset\n",
    "\n",
    "unique_session_ids = np.unique(groups)\n",
    "n_total_sessions = len(unique_session_ids)\n",
    "\n",
    "print(f\"Found {n_total_sessions} unique sessions (nights) in the dataset: {unique_session_ids}\")\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    unique_session_ids, \n",
    "    test_size=TEST_NIGHTS, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"\\nSplitting data into training and testing sets...\")\n",
    "print(f\"  - Sessions assigned to TRAINING set: {train_ids}\")\n",
    "print(f\"  - Sessions assigned to TESTING set:  {test_ids}\")\n",
    "\n",
    "train_mask = np.isin(groups, train_ids)\n",
    "test_mask = np.isin(groups, test_ids)\n",
    "\n",
    "# --- 4. Apply the masks to create the final data sets ---\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "# --- 5. Verify the results ---\n",
    "print(\"\\nTrain-test split complete.\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(f\"Total windows in training set:   {len(X_train)}\")\n",
    "print(f\"Total windows in testing set:    {len(X_test)}\")\n",
    "print(f\"Shape of X_train:                {X_train.shape}\")\n",
    "print(f\"Shape of X_test:                 {X_test.shape}\")\n",
    "print(f\"Training set class distribution: {Counter(y_train)} (0=Normal, 1=Apnea)\")\n",
    "print(f\"Testing set class distribution:  {Counter(y_test)} (0=Normal, 1=Apnea)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "768d4e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing the training data using SMOTE...\n",
      "  - Original training distribution: Counter({np.int64(0): 20839, np.int64(1): 535})\n",
      "  - Resampled training distribution: Counter({np.int64(0): 20839, np.int64(1): 20839})\n",
      "\n",
      "PyTorch DataLoaders created successfully.\n"
     ]
    }
   ],
   "source": [
    "nsamples, n_timesteps, n_features = X_train.shape\n",
    "X_train_reshaped = X_train.reshape((nsamples, n_timesteps * n_features))\n",
    "\n",
    "print(\"Balancing the training data using SMOTE...\")\n",
    "print(f\"  - Original training distribution: {Counter(y_train)}\")\n",
    "\n",
    "# --- 2. Initialize and apply SMOTE ---\n",
    "# `random_state` ensures that the synthetic samples are the same each time you run the code.\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_reshaped, y_train)\n",
    "\n",
    "print(f\"  - Resampled training distribution: {Counter(y_train_resampled)}\")\n",
    "\n",
    "# --- 3. Reshape the balanced training data back to its original 3D format ---\n",
    "# The model expects the data in the format (samples, timesteps, features).\n",
    "X_train_resampled = X_train_resampled.reshape((X_train_resampled.shape[0], n_timesteps, n_features))\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train_resampled).float()\n",
    "y_train_tensor = torch.from_numpy(y_train_resampled).long() # Use .long() for class indices\n",
    "\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders to handle batching and shuffling\n",
    "# BATCH_SIZE is from your configuration cell\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"\\nPyTorch DataLoaders created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be772b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c984a4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model created and moved to MPS device.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OSA_CNN(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv1d(2, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv_block2): Sequential(\n",
       "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv_block3): Sequential(\n",
       "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=11968, out_features=100, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class OSA_CNN(nn.Module):\n",
    "    def __init__(self, n_features, n_outputs):\n",
    "        super(OSA_CNN, self).__init__()\n",
    "        \n",
    "        # NOTE: PyTorch's Conv1d expects input shape (batch, features, timesteps)\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=n_features, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        # The output size of the conv blocks needs to be calculated to define the linear layer\n",
    "        # For an input of 375, after one MaxPool1d(2), the size becomes floor(375/2) = 187\n",
    "        flattened_size = 64 * 187 # (out_channels * sequence_length_after_pooling)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened_size, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, n_outputs) # Output raw logits for CrossEntropyLoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # --- CRITICAL STEP: Reshape input for PyTorch Conv1d ---\n",
    "        # Input x has shape (batch, timesteps, features)\n",
    "        # We permute it to (batch, features, timesteps)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # ----------------------------------------------------\n",
    "        \n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        \n",
    "        # Now pass the features to the classifier\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "\n",
    "# Instantiate the model and move it to the MPS device\n",
    "n_outputs = 2 # (Normal, Apnea)\n",
    "model = OSA_CNN(n_features=n_features, n_outputs=n_outputs).to(device)\n",
    "\n",
    "print(\"PyTorch model created and moved to MPS device.\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12acdbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyTorch model training...\n",
      "Epoch [1/50], Train Loss: 0.0060, Val Loss: 0.7210, Val Accuracy: 93.62%\n",
      "Epoch [2/50], Train Loss: 0.0030, Val Loss: 0.6463, Val Accuracy: 82.25%\n",
      "Epoch [3/50], Train Loss: 0.0029, Val Loss: 0.7998, Val Accuracy: 91.14%\n",
      "Epoch [4/50], Train Loss: 0.0036, Val Loss: 0.6978, Val Accuracy: 88.51%\n",
      "Epoch [5/50], Train Loss: 0.0051, Val Loss: 0.7925, Val Accuracy: 91.25%\n",
      "Epoch [6/50], Train Loss: 0.0029, Val Loss: 0.5611, Val Accuracy: 91.63%\n",
      "Epoch [7/50], Train Loss: 0.0044, Val Loss: 0.6700, Val Accuracy: 91.57%\n",
      "Epoch [8/50], Train Loss: 0.0059, Val Loss: 0.4854, Val Accuracy: 90.10%\n",
      "Epoch [9/50], Train Loss: 0.0055, Val Loss: 0.8728, Val Accuracy: 80.32%\n",
      "Epoch [10/50], Train Loss: 0.0032, Val Loss: 0.7035, Val Accuracy: 92.22%\n",
      "Epoch [11/50], Train Loss: 0.0040, Val Loss: 0.6009, Val Accuracy: 92.25%\n",
      "Epoch [12/50], Train Loss: 0.0024, Val Loss: 0.8736, Val Accuracy: 81.84%\n",
      "Epoch [13/50], Train Loss: 0.0026, Val Loss: 0.7246, Val Accuracy: 92.71%\n",
      "Epoch [14/50], Train Loss: 0.0056, Val Loss: 0.6567, Val Accuracy: 91.29%\n",
      "Epoch [15/50], Train Loss: 0.0035, Val Loss: 0.6661, Val Accuracy: 91.45%\n",
      "Epoch [16/50], Train Loss: 0.0024, Val Loss: 0.7692, Val Accuracy: 88.50%\n",
      "Epoch [17/50], Train Loss: 0.0047, Val Loss: 0.5751, Val Accuracy: 89.65%\n",
      "Epoch [18/50], Train Loss: 0.0050, Val Loss: 0.6810, Val Accuracy: 89.47%\n",
      "Epoch [19/50], Train Loss: 0.0044, Val Loss: 0.6566, Val Accuracy: 89.31%\n",
      "Epoch [20/50], Train Loss: 0.0021, Val Loss: 0.7329, Val Accuracy: 92.99%\n",
      "Epoch [21/50], Train Loss: 0.0045, Val Loss: 0.7629, Val Accuracy: 88.72%\n",
      "Epoch [22/50], Train Loss: 0.0053, Val Loss: 0.7745, Val Accuracy: 78.89%\n",
      "Epoch [23/50], Train Loss: 0.0029, Val Loss: 0.5911, Val Accuracy: 91.22%\n",
      "Epoch [24/50], Train Loss: 0.0014, Val Loss: 0.9130, Val Accuracy: 93.94%\n",
      "Epoch [25/50], Train Loss: 0.0036, Val Loss: 0.6993, Val Accuracy: 89.94%\n",
      "Epoch [26/50], Train Loss: 0.0054, Val Loss: 0.9884, Val Accuracy: 90.65%\n",
      "Epoch [27/50], Train Loss: 0.0074, Val Loss: 0.7521, Val Accuracy: 92.67%\n",
      "Epoch [28/50], Train Loss: 0.0033, Val Loss: 0.8017, Val Accuracy: 92.41%\n",
      "Epoch [29/50], Train Loss: 0.0036, Val Loss: 0.8763, Val Accuracy: 90.79%\n",
      "Epoch [30/50], Train Loss: 0.0045, Val Loss: 1.1600, Val Accuracy: 92.63%\n",
      "Epoch [31/50], Train Loss: 0.0023, Val Loss: 0.8992, Val Accuracy: 82.73%\n",
      "Epoch [32/50], Train Loss: 0.0022, Val Loss: 0.8847, Val Accuracy: 92.66%\n",
      "Epoch [33/50], Train Loss: 0.0035, Val Loss: 0.7605, Val Accuracy: 92.03%\n",
      "Epoch [34/50], Train Loss: 0.0028, Val Loss: 0.6282, Val Accuracy: 88.43%\n",
      "Epoch [35/50], Train Loss: 0.0039, Val Loss: 0.7510, Val Accuracy: 86.27%\n",
      "Epoch [36/50], Train Loss: 0.0046, Val Loss: 0.9155, Val Accuracy: 82.21%\n",
      "Epoch [37/50], Train Loss: 0.0059, Val Loss: 0.6965, Val Accuracy: 92.29%\n",
      "Epoch [38/50], Train Loss: 0.0024, Val Loss: 0.6734, Val Accuracy: 89.50%\n",
      "Epoch [39/50], Train Loss: 0.0011, Val Loss: 0.7712, Val Accuracy: 92.37%\n",
      "Epoch [40/50], Train Loss: 0.0030, Val Loss: 0.9272, Val Accuracy: 89.31%\n",
      "Epoch [41/50], Train Loss: 0.0029, Val Loss: 0.7283, Val Accuracy: 88.08%\n",
      "Epoch [42/50], Train Loss: 0.0032, Val Loss: 0.8939, Val Accuracy: 89.81%\n",
      "Epoch [43/50], Train Loss: 0.0041, Val Loss: 0.8705, Val Accuracy: 91.71%\n",
      "Epoch [44/50], Train Loss: 0.0020, Val Loss: 0.7609, Val Accuracy: 92.79%\n",
      "Epoch [45/50], Train Loss: 0.0020, Val Loss: 0.9468, Val Accuracy: 91.03%\n",
      "Epoch [46/50], Train Loss: 0.0031, Val Loss: 1.1580, Val Accuracy: 91.85%\n",
      "Epoch [47/50], Train Loss: 0.0017, Val Loss: 0.8119, Val Accuracy: 90.06%\n",
      "Epoch [48/50], Train Loss: 0.0038, Val Loss: 0.8718, Val Accuracy: 91.97%\n",
      "Epoch [49/50], Train Loss: 0.0103, Val Loss: 0.6531, Val Accuracy: 85.78%\n",
      "Epoch [50/50], Train Loss: 0.0033, Val Loss: 0.7899, Val Accuracy: 92.90%\n",
      "\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "weight_for_apnea = Counter(y_train)[0]/Counter(y_train)[1] \n",
    "class_weights = torch.tensor([1.0, weight_for_apnea]).float().to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights) # This loss function is perfect for multi-class classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# --- Training Loop ---\n",
    "print(\"Starting PyTorch model training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train() # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Iterate over batches of data from the DataLoader\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Move data to the selected device (MPS)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # 1. Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 3. Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 4. Backward pass (calculate gradients)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Update the model's weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # Disable gradient calculation for validation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nModel training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fce3e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating final model on the test set...\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Normal (0)       0.95      0.97      0.96      7119\n",
      "   Apnea (1)       0.16      0.10      0.12       375\n",
      "\n",
      "    accuracy                           0.93      7494\n",
      "   macro avg       0.56      0.54      0.54      7494\n",
      "weighted avg       0.91      0.93      0.92      7494\n",
      "\n",
      "Confusion Matrix\n",
      "----------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Evaluating final model on the test set...\")\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# --- Classification Report and Confusion Matrix ---\n",
    "print('\\nClassification Report')\n",
    "print('---------------------')\n",
    "class_names = ['Normal (0)', 'Apnea (1)']\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print('----------------')\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm_norm, annot=True, fmt='.2%', cmap='Blues', \n",
    "    xticklabels=class_names, yticklabels=class_names\n",
    ")\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e29e980",
   "metadata": {},
   "source": [
    "*Leave one out Cross validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9903739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Leave-One-Night-Out cross-validation with 9 folds...\n",
      "----------------------------------------------------\n",
      "\n",
      "--- FOLD 1/9 ---\n",
      "Testing on Night: 04-04-2025\n",
      "\n",
      "  - Original training distribution for this fold: Counter({np.int64(0): 24608, np.int64(1): 709})\n",
      "  - Resampled training distribution: Counter({np.int64(0): 24608, np.int64(1): 24608})\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     57\u001b[39m inputs, labels = inputs.to(device), labels.to(device)\n\u001b[32m     58\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     61\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mOSA_CNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     38\u001b[39m x = x.permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# ----------------------------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv_block1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m x = \u001b[38;5;28mself\u001b[39m.conv_block2(x)\n\u001b[32m     43\u001b[39m x = \u001b[38;5;28mself\u001b[39m.conv_block3(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n\u001b[32m   1753\u001b[39m \u001b[38;5;66;03m# torchrec tests the code consistency with the following code\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1756\u001b[39m     forward_call = (\u001b[38;5;28mself\u001b[39m._slow_forward \u001b[38;5;28;01mif\u001b[39;00m torch._C._get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward)\n\u001b[32m   1757\u001b[39m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_fold_predictions = []\n",
    "all_fold_true_labels = []\n",
    "\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "n_folds = logo.get_n_splits(groups=groups)\n",
    "print(f\"Starting Leave-One-Night-Out cross-validation with {n_folds} folds...\")\n",
    "print(\"----------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "# --- 2. Loop through each fold ---\n",
    "for fold, (train_idx, test_idx) in enumerate(logo.split(X, y, groups)):\n",
    "    \n",
    "    # Identify which night is being left out for testing in this fold\n",
    "    test_night = np.unique(groups[test_idx])[0]\n",
    "    print(f\"--- FOLD {fold + 1}/{n_folds} ---\")\n",
    "    print(f\"Testing on Night: {test_night}\\n\")\n",
    "\n",
    "    # --- 3. Split the data for this fold ---\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # --- 4. Balance the TRAINING data for this fold ---\n",
    "    print(f\"  - Original training distribution for this fold: {Counter(y_train)}\")\n",
    "    nsamples, n_timesteps, n_features = X_train.shape\n",
    "    X_train_reshaped = X_train.reshape((nsamples, n_timesteps * n_features))\n",
    "    \n",
    "    smote = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_reshaped, y_train)\n",
    "    X_train_resampled = X_train_resampled.reshape(-1, n_timesteps, n_features)\n",
    "    print(f\"  - Resampled training distribution: {Counter(y_train_resampled)}\")\n",
    "\n",
    "    # --- 5. Create PyTorch DataLoaders for this fold ---\n",
    "    X_train_tensor = torch.from_numpy(X_train_resampled).float()\n",
    "    y_train_tensor = torch.from_numpy(y_train_resampled).long()\n",
    "    X_test_tensor = torch.from_numpy(X_test).float()\n",
    "    y_test_tensor = torch.from_numpy(y_test).long()\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # --- 6. Initialize and Train a NEW model for this fold ---\n",
    "    # It's crucial to re-initialize the model for each fold to avoid leakage.\n",
    "    model = OSA_CNN(n_features=n_features, n_outputs=2).to(device)\n",
    "    \n",
    "    # Define loss and optimizer (with class weights if you're using them)\n",
    "    criterion = nn.CrossEntropyLoss() # <-- Add your class weights here if needed\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    # (The full training loop from the previous step goes here)\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(f\"\\n  - Training complete for fold {fold + 1}.\")\n",
    "            \n",
    "    # --- 7. Evaluate the fold and store results ---\n",
    "    model.eval()\n",
    "    fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            fold_preds.extend(predicted.cpu().numpy())\n",
    "            \n",
    "    all_fold_predictions.extend(fold_preds)\n",
    "    all_fold_true_labels.extend(y_test)\n",
    "    print(f\"  - Evaluation complete for fold {fold + 1}.\\n\")\n",
    "\n",
    "\n",
    "# --- FINAL AGGREGATED EVALUATION (after all folds are complete) ---\n",
    "print(\"\\n====================================================\")\n",
    "print(\"Leave-One-Night-Out Cross-Validation Complete.\")\n",
    "print(\"Aggregated Results Across All Folds:\")\n",
    "print(\"====================================================\")\n",
    "\n",
    "# --- Final Classification Report ---\n",
    "print('\\nAggregated Classification Report')\n",
    "print('------------------------------')\n",
    "class_names = ['Normal (0)', 'Apnea (1)']\n",
    "print(classification_report(all_fold_true_labels, all_fold_predictions, target_names=class_names))\n",
    "\n",
    "# --- Final Confusion Matrix ---\n",
    "print('Aggregated Confusion Matrix')\n",
    "print('---------------------------')\n",
    "cm = confusion_matrix(all_fold_true_labels, all_fold_predictions)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm_norm, annot=True, fmt='.2%', cmap='Blues', \n",
    "    xticklabels=class_names, yticklabels=class_names\n",
    ")\n",
    "plt.title('Aggregated Normalized Confusion Matrix (LONO)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc7432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
