{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df119221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import pytz\n",
    "import os\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96248335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 event files. Processing each one...\n",
      "  - Processing session: 26-04-2025\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 08-05-2025\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 05-04-2025\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 10-05-2025\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 24-04-2025\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 25-04-2025\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 16-04-2025\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 11-05-2025\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 04-04-2025\n",
      "  - Applying precise interval-based labels...\n",
      "\n",
      "----------------------------------------------------\n",
      "Data loading with PRECISE interval labeling complete.\n",
      "Final DataFrame shape: (2139235, 24)\n",
      "Final class distribution in raw data: \n",
      "Label\n",
      "0    0.925862\n",
      "1    0.074138\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load in Data\n",
    "EVENTS_FOLDER = '../../data/bishkek_csr/03_train_ready/event_exports' \n",
    "RESPECK_FOLDER = '../../data/bishkek_csr/03_train_ready/respeck'\n",
    "NASAL_FOLDER = '../../data/bishkek_csr/03_train_ready/nasal_files'\n",
    "\n",
    "# --- Define relevant events ---\n",
    "APNEA_EVENT_LABELS = [\n",
    "    'Obstructive Apnea', 'Central Apnea', 'Mixed Apnea', 'Hypopnea'\n",
    " ]\n",
    "# all_sessions_df_list = []\n",
    "# event_files = glob.glob(os.path.join(EVENTS_FOLDER, '*_event_export.csv'))\n",
    "\n",
    "# if not event_files:\n",
    "#     raise FileNotFoundError(f\"No event files found in '{EVENTS_FOLDER}'. Please check the path.\")\n",
    "\n",
    "# print(f\"Found {len(event_files)} event files. Processing each one...\")\n",
    "\n",
    "# for event_file_path in event_files:\n",
    "#     # --- 1. Setup paths and IDs ---\n",
    "#     base_name = os.path.basename(event_file_path)\n",
    "#     session_id = base_name.split('_event_export.csv')[0]\n",
    "#     respeck_file_path = os.path.join(RESPECK_FOLDER, f'{session_id}_respeck.csv')\n",
    "#     nasal_file_path = os.path.join(NASAL_FOLDER, f'{session_id}_nasal.csv')\n",
    "\n",
    "#     if not os.path.exists(respeck_file_path):\n",
    "#         print(f\"  - WARNING: Skipping session '{session_id}'. No matching Respeck file found.\")\n",
    "#         continue\n",
    "#     print(f\"  - Processing session: {session_id}\")\n",
    "\n",
    "#     df_nasal = pd.read_csv(nasal_file_path)\n",
    "#     df_nasal.rename(columns={'UnixTimestamp': 'timestamp_unix'}, inplace=True, errors='ignore')\n",
    "\n",
    "#     # --- 2. Load ALL event data (NO initial filtering) ---\n",
    "#     df_events = pd.read_csv(event_file_path, decimal=',')\n",
    "    \n",
    "#     # --- 3. Create the new binary 'Label' column ---\n",
    "#     # If the 'Event' is in our target list, label is 1 (Apnea).\n",
    "#     # Otherwise, for ALL other event types, label is 0 (Normal).\n",
    "#     df_events['Label'] = df_events['Event'].isin(APNEA_EVENT_LABELS).astype(int)\n",
    "    \n",
    "#     # --- 4. Load Respeck data ---\n",
    "#     df_respeck = pd.read_csv(respeck_file_path)\n",
    "    \n",
    "#     # --- 5. Prepare for merging (using Unix timestamps) ---\n",
    "#     df_respeck.rename(columns={'alignedTimestamp': 'UnixTimestamp'}, inplace=True)\n",
    "#     df_events.rename(columns={'UnixTimestamp': 'timestamp_unix'}, inplace=True)\n",
    "#     df_respeck.rename(columns={'UnixTimestamp': 'timestamp_unix'}, inplace=True)\n",
    "\n",
    "#     df_events['timestamp_unix'] = df_events['timestamp_unix'].astype('int64')\n",
    "#     df_respeck['timestamp_unix'] = df_respeck['timestamp_unix'].astype('int64')\n",
    "\n",
    "#     df_respeck.sort_values('timestamp_unix', inplace=True)\n",
    "#     df_events.sort_values('timestamp_unix', inplace=True)\n",
    "\n",
    "#     start_time = max(df_nasal['timestamp_unix'].min(), df_respeck['timestamp_unix'].min())\n",
    "#     end_time = min(df_nasal['timestamp_unix'].max(), df_respeck['timestamp_unix'].max())\n",
    "\n",
    "#     df_respeck = df_respeck[(df_respeck['timestamp_unix'] >= start_time) & (df_respeck['timestamp_unix'] <= end_time)].copy()\n",
    "#     # df_events = df_events[(df_events['timestamp_unix'] >= start_time) & (df_events['timestamp_unix'] <= end_time)].copy()\n",
    "\n",
    "#     if df_respeck.empty or df_events.empty:\n",
    "#         print(f\"  - WARNING: Skipping session '{session_id}'. No overlapping data found in the calculated time range.\")\n",
    "    \n",
    "#     # --- 6. Merge the data (now merging the new binary 'Label' column) ---\n",
    "#     df_merged = pd.merge_asof(\n",
    "#         df_respeck,\n",
    "#         df_events[['timestamp_unix', 'Label']], # Only need the timestamp and our new 0/1 Label\n",
    "#         on='timestamp_unix',\n",
    "#         direction='backward'\n",
    "#     )\n",
    "    \n",
    "#     # --- 7. Final cleanup ---\n",
    "#     # Any sensor data before the VERY FIRST event will be NaN. These are Normal.\n",
    "#     # So we fill any remaining NaNs with 0.\n",
    "#     df_merged['Label'].fillna(0, inplace=True)\n",
    "    \n",
    "#     df_merged['SessionID'] = session_id\n",
    "#     all_sessions_df_list.append(df_merged)\n",
    "\n",
    "# # --- Combine all nights and perform final processing ---\n",
    "# if not all_sessions_df_list:\n",
    "#     raise ValueError(\"Processing failed. No data was loaded.\")\n",
    "\n",
    "# df = pd.concat(all_sessions_df_list, ignore_index=True)\n",
    "\n",
    "# # Add one-hot encoded activity features (position)\n",
    "# df = pd.get_dummies(df, columns=['activityType'], prefix='activity')\n",
    "\n",
    "# # (Your NaN imputation and Sav-Gol filter blocks should follow here)\n",
    "\n",
    "# print(\"\\n----------------------------------------------------\")\n",
    "# print(\"Data loading with CORRECTED labeling complete.\")\n",
    "# print(f\"Final DataFrame shape: {df.shape}\")\n",
    "# print(f\"Final class distribution in raw data: \\n{df['Label'].value_counts(normalize=True)}\")\n",
    "\n",
    "# --- Main Processing Loop with Precise Interval-Based Labeling ---\n",
    "all_sessions_df_list = []\n",
    "event_files = glob.glob(os.path.join(EVENTS_FOLDER, '*_event_export.csv'))\n",
    "\n",
    "if not event_files:\n",
    "    raise FileNotFoundError(f\"No event files found in '{EVENTS_FOLDER}'.\")\n",
    "\n",
    "print(f\"Found {len(event_files)} event files. Processing each one...\")\n",
    "\n",
    "for event_file_path in event_files:\n",
    "    # --- 1. Setup paths and IDs ---\n",
    "    base_name = os.path.basename(event_file_path)\n",
    "    session_id = base_name.split('_event_export.csv')[0]\n",
    "    respeck_file_path = os.path.join(RESPECK_FOLDER, f'{session_id}_respeck.csv')\n",
    "    nasal_file_path = os.path.join(NASAL_FOLDER, f'{session_id}_nasal.csv')\n",
    "    \n",
    "    if not all(os.path.exists(p) for p in [respeck_file_path, nasal_file_path]):\n",
    "        print(f\"  - WARNING: Skipping session '{session_id}'. A corresponding file is missing.\")\n",
    "        continue\n",
    "    print(f\"  - Processing session: {session_id}\")\n",
    "    \n",
    "    # --- 2. Load all data sources ---\n",
    "    df_events = pd.read_csv(event_file_path, decimal=',')\n",
    "    df_nasal = pd.read_csv(nasal_file_path)\n",
    "    df_respeck = pd.read_csv(respeck_file_path)\n",
    "\n",
    "    # --- 3. Standardize timestamp columns and types ---\n",
    "    df_events.rename(columns={'UnixTimestamp': 'timestamp_unix'}, inplace=True)\n",
    "    df_nasal.rename(columns={'UnixTimestamp': 'timestamp_unix'}, inplace=True, errors='ignore')\n",
    "    df_respeck.rename(columns={'alignedTimestamp': 'timestamp_unix'}, inplace=True)\n",
    "    \n",
    "    for df_ in [df_events, df_nasal, df_respeck]:\n",
    "        df_['timestamp_unix'] = pd.to_numeric(df_['timestamp_unix'], errors='coerce')\n",
    "        df_.dropna(subset=['timestamp_unix'], inplace=True)\n",
    "        df_['timestamp_unix'] = df_['timestamp_unix'].astype('int64')\n",
    "\n",
    "    # --- 4. Calculate the true overlapping time range ---\n",
    "    start_time = max(df_nasal['timestamp_unix'].min(), df_respeck['timestamp_unix'].min())\n",
    "    end_time = min(df_nasal['timestamp_unix'].max(), df_respeck['timestamp_unix'].max())\n",
    "    \n",
    "    # --- 5. Trim Respeck data to the overlapping time range ---\n",
    "    df_respeck = df_respeck[(df_respeck['timestamp_unix'] >= start_time) & (df_respeck['timestamp_unix'] <= end_time)].copy()\n",
    "\n",
    "    if df_respeck.empty:\n",
    "        print(f\"  - WARNING: Skipping session '{session_id}'. No Respeck data in the overlapping range.\")\n",
    "        continue\n",
    "        \n",
    "    # --- 6. **NEW: Precise Interval-Based Labeling using Duration** ---\n",
    "    print(f\"  - Applying precise interval-based labels...\")\n",
    "    \n",
    "    # ** Step 6a: Initialize the label column in the respeck data with 0 (Normal)\n",
    "    df_respeck['Label'] = 0\n",
    "    \n",
    "    # ** Step 6b: Calculate event end times using the 'Duration' column\n",
    "    # The 'Duration' column has commas, which we handled with `decimal=','` at load time.\n",
    "    # Convert duration from seconds to milliseconds to match the Unix timestamps.\n",
    "    df_events['Duration_ms'] = (df_events['Duration'] * 1000).astype('int64')\n",
    "    df_events['end_time_unix'] = df_events['timestamp_unix'] + df_events['Duration_ms']\n",
    "    \n",
    "    # ** Step 6c: Filter for only the apnea/hypopnea events we want to label as '1'\n",
    "    df_apnea_events = df_events[df_events['Event'].isin(APNEA_EVENT_LABELS)].copy()\n",
    "\n",
    "    # ** Step 6d: Efficiently label the respeck data using event intervals\n",
    "    # This is much faster than looping. It checks which respeck timestamps fall\n",
    "    # within any of the [start, end] intervals of the apnea events.\n",
    "    for index, event in df_apnea_events.iterrows():\n",
    "        start_event = event['timestamp_unix']\n",
    "        end_event = event['end_time_unix']\n",
    "        # Set the 'Label' to 1 for all respeck rows within this event's time interval\n",
    "        df_respeck.loc[df_respeck['timestamp_unix'].between(start_event, end_event), 'Label'] = 1\n",
    "\n",
    "    # --- 7. Finalize session data ---\n",
    "    df_respeck['SessionID'] = session_id\n",
    "    all_sessions_df_list.append(df_respeck)\n",
    "\n",
    "# --- Combine all nights and perform final processing ---\n",
    "if not all_sessions_df_list:\n",
    "    raise ValueError(\"Processing failed. No data was loaded.\")\n",
    "\n",
    "df = pd.concat(all_sessions_df_list, ignore_index=True)\n",
    "\n",
    "# Add one-hot encoded activity features\n",
    "df = pd.get_dummies(df, columns=['activityType'], prefix='activity')\n",
    "\n",
    "# ... (NaN imputation and Sav-Gol filter blocks should follow here) ...\n",
    "\n",
    "print(\"\\n----------------------------------------------------\")\n",
    "print(\"Data loading with PRECISE interval labeling complete.\")\n",
    "print(f\"Final DataFrame shape: {df.shape}\")\n",
    "print(f\"Final class distribution in raw data: \\n{df['Label'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ea2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windowing: Creating the time-series segments.\n",
    "\n",
    "SAMPLING_RATE_HZ = 12.5\n",
    "WINDOW_DURATION_SEC = 30\n",
    "WINDOW_SIZE = int(WINDOW_DURATION_SEC * SAMPLING_RATE_HZ)\n",
    "\n",
    "# Step size for sliding window. An 80% overlap is a good start.\n",
    "OVERLAP_PERCENTAGE = 0.80\n",
    "STEP_SIZE = int(WINDOW_SIZE * (1 - OVERLAP_PERCENTAGE))\n",
    "\n",
    "# === Data Parameters ===\n",
    "FEATURE_COLUMNS = [\n",
    "    'breathingSignal', \n",
    "    'activityLevel',\n",
    "]\n",
    "LABEL_COLUMN = 'Label' \n",
    "SESSION_ID_COLUMN = 'SessionID'\n",
    "\n",
    "\n",
    "TEST_NIGHTS = 2\n",
    "TOTAL_NIGHTS = 9 \n",
    "TEST_SIZE = TEST_NIGHTS / TOTAL_NIGHTS\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e53241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for and imputing missing values (NaNs)...\n",
      "  - Found 4630 NaNs in 'breathingSignal'. Applying forward-fill and backward-fill.\n",
      "\n",
      "Imputation complete. No NaNs remain in feature columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qj/1f20_52j2yj49hjhy3ht9wzw0000gn/T/ipykernel_90616/1175957762.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].ffill(inplace=True)\n",
      "/var/folders/qj/1f20_52j2yj49hjhy3ht9wzw0000gn/T/ipykernel_90616/1175957762.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].bfill(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChecking for and imputing missing values (NaNs)...\")\n",
    "for col in ['breathingSignal', 'activityLevel', 'x', 'y', 'z']:\n",
    "    if col in df.columns:\n",
    "        nan_count = df[col].isnull().sum()\n",
    "        if nan_count > 0:\n",
    "            print(f\"  - Found {nan_count} NaNs in '{col}'. Applying forward-fill and backward-fill.\")\n",
    "            \n",
    "            # Step 1: Forward-fill handles all NaNs except leading ones.\n",
    "            df[col].ffill(inplace=True) \n",
    "            \n",
    "            # Step 2: Backward-fill handles any remaining NaNs at the beginning of the file.\n",
    "            df[col].bfill(inplace=True) \n",
    "\n",
    "# Add a final check to ensure everything is clean\n",
    "final_nan_count = df[FEATURE_COLUMNS].isnull().sum().sum()\n",
    "if final_nan_count > 0:\n",
    "    print(f\"\\nWARNING: {final_nan_count} NaNs still remain in feature columns after imputation. Please investigate.\")\n",
    "else:\n",
    "    print(\"\\nImputation complete. No NaNs remain in feature columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ed1b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the windowing process...\n",
      "\n",
      "Data windowing complete.\n",
      "----------------------------------------------------\n",
      "Shape of X (features): (28868, 375, 2) -> (Num_Windows, Window_Size, Num_Features)\n",
      "Shape of y (labels):   (28868,)\n",
      "Shape of groups (IDs): (28868,)\n",
      "Final class distribution across all windows: Counter({np.int64(0): 24843, np.int64(1): 4025}) (0=Normal, 1=Apnea)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "groups = [] \n",
    "\n",
    "print(\"Starting the windowing process...\")\n",
    "\n",
    "# --- 3. Loop through each session (night) to create windows ---\n",
    "# We group by SessionID to ensure windows do not cross over between nights.\n",
    "for session_id, session_df in df.groupby(SESSION_ID_COLUMN):\n",
    "    for i in range(0, len(session_df) - WINDOW_SIZE, STEP_SIZE):\n",
    "        \n",
    "        window_df = session_df.iloc[i : i + WINDOW_SIZE]\n",
    "        \n",
    "        features = window_df[FEATURE_COLUMNS].values\n",
    "        \n",
    "        # --- CORRECTED LABELING LOGIC ---\n",
    "        # The 'Label' column already contains 0s and 1s.\n",
    "        # If the sum of labels in the window is > 0, it means there's at least one '1' (Apnea).\n",
    "        if window_df[LABEL_COLUMN].sum() > 0:\n",
    "            label = 1 # Apnea\n",
    "        else:\n",
    "            label = 0 # Normal\n",
    "        # ------------------------------------\n",
    "            \n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "        groups.append(session_id)\n",
    "\n",
    "# --- 4. Convert the lists into efficient NumPy arrays ---\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "groups = np.asarray(groups)\n",
    "\n",
    "# --- 5. Print a summary of the results ---\n",
    "print(\"\\nData windowing complete.\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(f\"Shape of X (features): {X.shape} -> (Num_Windows, Window_Size, Num_Features)\")\n",
    "print(f\"Shape of y (labels):   {y.shape}\")\n",
    "print(f\"Shape of groups (IDs): {groups.shape}\")\n",
    "print(f\"Final class distribution across all windows: {Counter(y)} (0=Normal, 1=Apnea)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475c0f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 unique sessions (nights) in the dataset: ['04-04-2025' '05-04-2025' '08-05-2025' '10-05-2025' '11-05-2025'\n",
      " '16-04-2025' '24-04-2025' '25-04-2025' '26-04-2025']\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "  - Sessions assigned to TRAINING set: ['16-04-2025' '04-04-2025' '26-04-2025' '08-05-2025' '11-05-2025'\n",
      " '10-05-2025' '24-04-2025']\n",
      "  - Sessions assigned to TESTING set:  ['25-04-2025' '05-04-2025']\n",
      "\n",
      "Train-test split complete.\n",
      "----------------------------------------------------\n",
      "Total windows in training set:   21374\n",
      "Total windows in testing set:    7494\n",
      "Shape of X_train:                (21374, 375, 2)\n",
      "Shape of X_test:                 (7494, 375, 2)\n",
      "Training set class distribution: Counter({np.int64(0): 18902, np.int64(1): 2472}) (0=Normal, 1=Apnea)\n",
      "Testing set class distribution:  Counter({np.int64(0): 5941, np.int64(1): 1553}) (0=Normal, 1=Apnea)\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset\n",
    "\n",
    "unique_session_ids = np.unique(groups)\n",
    "n_total_sessions = len(unique_session_ids)\n",
    "\n",
    "print(f\"Found {n_total_sessions} unique sessions (nights) in the dataset: {unique_session_ids}\")\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    unique_session_ids, \n",
    "    test_size=TEST_NIGHTS, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"\\nSplitting data into training and testing sets...\")\n",
    "print(f\"  - Sessions assigned to TRAINING set: {train_ids}\")\n",
    "print(f\"  - Sessions assigned to TESTING set:  {test_ids}\")\n",
    "\n",
    "train_mask = np.isin(groups, train_ids)\n",
    "test_mask = np.isin(groups, test_ids)\n",
    "\n",
    "# --- 4. Apply the masks to create the final data sets ---\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "# --- 5. Verify the results ---\n",
    "print(\"\\nTrain-test split complete.\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(f\"Total windows in training set:   {len(X_train)}\")\n",
    "print(f\"Total windows in testing set:    {len(X_test)}\")\n",
    "print(f\"Shape of X_train:                {X_train.shape}\")\n",
    "print(f\"Shape of X_test:                 {X_test.shape}\")\n",
    "print(f\"Training set class distribution: {Counter(y_train)} (0=Normal, 1=Apnea)\")\n",
    "print(f\"Testing set class distribution:  {Counter(y_test)} (0=Normal, 1=Apnea)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768d4e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing the training data using SMOTE...\n",
      "  - Original training distribution: Counter({np.int64(0): 18902, np.int64(1): 2472})\n",
      "  - Resampled training distribution: Counter({np.int64(0): 18902, np.int64(1): 18902})\n",
      "\n",
      "PyTorch DataLoaders created successfully.\n"
     ]
    }
   ],
   "source": [
    "nsamples, n_timesteps, n_features = X_train.shape\n",
    "X_train_reshaped = X_train.reshape((nsamples, n_timesteps * n_features))\n",
    "\n",
    "print(\"Balancing the training data using SMOTE...\")\n",
    "print(f\"  - Original training distribution: {Counter(y_train)}\")\n",
    "\n",
    "# --- 2. Initialize and apply SMOTE ---\n",
    "# `random_state` ensures that the synthetic samples are the same each time you run the code.\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_reshaped, y_train)\n",
    "\n",
    "print(f\"  - Resampled training distribution: {Counter(y_train_resampled)}\")\n",
    "\n",
    "# --- 3. Reshape the balanced training data back to its original 3D format ---\n",
    "# The model expects the data in the format (samples, timesteps, features).\n",
    "X_train_resampled = X_train_resampled.reshape((X_train_resampled.shape[0], n_timesteps, n_features))\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train_resampled).float()\n",
    "y_train_tensor = torch.from_numpy(y_train_resampled).long() # Use .long() for class indices\n",
    "\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders to handle batching and shuffling\n",
    "# BATCH_SIZE is from your configuration cell\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"\\nPyTorch DataLoaders created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be772b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c984a4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model created and moved to MPS device.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OSA_CNN(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv1d(2, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv_block2): Sequential(\n",
       "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv_block3): Sequential(\n",
       "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=11968, out_features=100, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell_type: \"code\"\n",
    "class OSA_CNN(nn.Module):\n",
    "    def __init__(self, n_features, n_outputs):\n",
    "        super(OSA_CNN, self).__init__()\n",
    "        \n",
    "        # NOTE: PyTorch's Conv1d expects input shape (batch, features, timesteps)\n",
    "        # Keras expects (batch, timesteps, features). We will handle this in the forward pass.\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=n_features, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        # The output size of the conv blocks needs to be calculated to define the linear layer\n",
    "        # For an input of 375, after one MaxPool1d(2), the size becomes floor(375/2) = 187\n",
    "        flattened_size = 64 * 187 # (out_channels * sequence_length_after_pooling)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened_size, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, n_outputs) # Output raw logits for CrossEntropyLoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # --- CRITICAL STEP: Reshape input for PyTorch Conv1d ---\n",
    "        # Input x has shape (batch, timesteps, features)\n",
    "        # We permute it to (batch, features, timesteps)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # ----------------------------------------------------\n",
    "        \n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        \n",
    "        # Now pass the features to the classifier\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "\n",
    "# Instantiate the model and move it to the MPS device\n",
    "n_outputs = 2 # (Normal, Apnea)\n",
    "model = OSA_CNN(n_features=n_features, n_outputs=n_outputs).to(device)\n",
    "\n",
    "print(\"PyTorch model created and moved to MPS device.\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12acdbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyTorch model training...\n",
      "Epoch [1/100], Train Loss: 0.6690, Val Loss: 0.7368, Val Accuracy: 41.81%\n",
      "Epoch [2/100], Train Loss: 0.5724, Val Loss: 0.5894, Val Accuracy: 71.27%\n",
      "Epoch [3/100], Train Loss: 0.4959, Val Loss: 0.6700, Val Accuracy: 63.25%\n",
      "Epoch [4/100], Train Loss: 0.4604, Val Loss: 0.8650, Val Accuracy: 49.23%\n",
      "Epoch [5/100], Train Loss: 0.4230, Val Loss: 0.6927, Val Accuracy: 64.25%\n",
      "Epoch [6/100], Train Loss: 0.4019, Val Loss: 0.7225, Val Accuracy: 62.04%\n",
      "Epoch [7/100], Train Loss: 0.3718, Val Loss: 0.6603, Val Accuracy: 67.75%\n",
      "Epoch [8/100], Train Loss: 0.3469, Val Loss: 0.5652, Val Accuracy: 74.67%\n",
      "Epoch [9/100], Train Loss: 0.3205, Val Loss: 0.7454, Val Accuracy: 62.65%\n",
      "Epoch [10/100], Train Loss: 0.2984, Val Loss: 0.5738, Val Accuracy: 76.85%\n",
      "Epoch [11/100], Train Loss: 0.2790, Val Loss: 0.6461, Val Accuracy: 73.83%\n",
      "Epoch [12/100], Train Loss: 0.2496, Val Loss: 0.8863, Val Accuracy: 61.42%\n",
      "Epoch [13/100], Train Loss: 0.2310, Val Loss: 0.6088, Val Accuracy: 74.50%\n",
      "Epoch [14/100], Train Loss: 0.2106, Val Loss: 0.6027, Val Accuracy: 75.49%\n",
      "Epoch [15/100], Train Loss: 0.1921, Val Loss: 0.6028, Val Accuracy: 78.72%\n",
      "Epoch [16/100], Train Loss: 0.1716, Val Loss: 0.6412, Val Accuracy: 76.83%\n",
      "Epoch [17/100], Train Loss: 0.1595, Val Loss: 0.6180, Val Accuracy: 76.46%\n",
      "Epoch [18/100], Train Loss: 0.1436, Val Loss: 0.6479, Val Accuracy: 76.46%\n",
      "Epoch [19/100], Train Loss: 0.1323, Val Loss: 0.7566, Val Accuracy: 72.35%\n",
      "Epoch [20/100], Train Loss: 0.1153, Val Loss: 0.9626, Val Accuracy: 70.59%\n",
      "Epoch [21/100], Train Loss: 0.1065, Val Loss: 0.6694, Val Accuracy: 79.80%\n",
      "Epoch [22/100], Train Loss: 0.0958, Val Loss: 0.8590, Val Accuracy: 69.04%\n",
      "Epoch [23/100], Train Loss: 0.0893, Val Loss: 0.8968, Val Accuracy: 71.67%\n",
      "Epoch [24/100], Train Loss: 0.0803, Val Loss: 0.7141, Val Accuracy: 78.25%\n",
      "Epoch [25/100], Train Loss: 0.0711, Val Loss: 0.7497, Val Accuracy: 79.97%\n",
      "Epoch [26/100], Train Loss: 0.0672, Val Loss: 0.7943, Val Accuracy: 77.16%\n",
      "Epoch [27/100], Train Loss: 0.0601, Val Loss: 0.9584, Val Accuracy: 72.02%\n",
      "Epoch [28/100], Train Loss: 0.0548, Val Loss: 0.7642, Val Accuracy: 79.70%\n",
      "Epoch [29/100], Train Loss: 0.0532, Val Loss: 0.7624, Val Accuracy: 80.17%\n",
      "Epoch [30/100], Train Loss: 0.0465, Val Loss: 0.9440, Val Accuracy: 77.21%\n",
      "Epoch [31/100], Train Loss: 0.0419, Val Loss: 0.7963, Val Accuracy: 78.60%\n",
      "Epoch [32/100], Train Loss: 0.0365, Val Loss: 0.8356, Val Accuracy: 80.70%\n",
      "Epoch [33/100], Train Loss: 0.0412, Val Loss: 0.9040, Val Accuracy: 77.61%\n",
      "Epoch [34/100], Train Loss: 0.0372, Val Loss: 0.8307, Val Accuracy: 79.29%\n",
      "Epoch [35/100], Train Loss: 0.0358, Val Loss: 0.9186, Val Accuracy: 80.77%\n",
      "Epoch [36/100], Train Loss: 0.0304, Val Loss: 0.8867, Val Accuracy: 80.66%\n",
      "Epoch [37/100], Train Loss: 0.0293, Val Loss: 1.0571, Val Accuracy: 77.72%\n",
      "Epoch [38/100], Train Loss: 0.0316, Val Loss: 0.9850, Val Accuracy: 80.09%\n",
      "Epoch [39/100], Train Loss: 0.0219, Val Loss: 0.9499, Val Accuracy: 79.73%\n",
      "Epoch [40/100], Train Loss: 0.0278, Val Loss: 0.9996, Val Accuracy: 79.77%\n",
      "Epoch [41/100], Train Loss: 0.0247, Val Loss: 1.0844, Val Accuracy: 80.81%\n",
      "Epoch [42/100], Train Loss: 0.0250, Val Loss: 1.0633, Val Accuracy: 78.86%\n",
      "Epoch [43/100], Train Loss: 0.0255, Val Loss: 1.0021, Val Accuracy: 79.00%\n",
      "Epoch [44/100], Train Loss: 0.0249, Val Loss: 1.0333, Val Accuracy: 78.46%\n",
      "Epoch [45/100], Train Loss: 0.0233, Val Loss: 1.0058, Val Accuracy: 78.44%\n",
      "Epoch [46/100], Train Loss: 0.0205, Val Loss: 1.0099, Val Accuracy: 80.86%\n",
      "Epoch [47/100], Train Loss: 0.0199, Val Loss: 1.0515, Val Accuracy: 79.28%\n",
      "Epoch [48/100], Train Loss: 0.0174, Val Loss: 1.0495, Val Accuracy: 76.42%\n",
      "Epoch [49/100], Train Loss: 0.0172, Val Loss: 1.1769, Val Accuracy: 79.92%\n",
      "Epoch [50/100], Train Loss: 0.0163, Val Loss: 1.0936, Val Accuracy: 80.32%\n",
      "Epoch [51/100], Train Loss: 0.0150, Val Loss: 1.1033, Val Accuracy: 79.70%\n",
      "Epoch [52/100], Train Loss: 0.0140, Val Loss: 1.1589, Val Accuracy: 80.22%\n",
      "Epoch [53/100], Train Loss: 0.0119, Val Loss: 1.2263, Val Accuracy: 80.33%\n",
      "Epoch [54/100], Train Loss: 0.0173, Val Loss: 1.0978, Val Accuracy: 80.65%\n",
      "Epoch [55/100], Train Loss: 0.0138, Val Loss: 1.2225, Val Accuracy: 80.56%\n",
      "Epoch [56/100], Train Loss: 0.0146, Val Loss: 1.1552, Val Accuracy: 80.50%\n",
      "Epoch [57/100], Train Loss: 0.0118, Val Loss: 1.0756, Val Accuracy: 80.54%\n",
      "Epoch [58/100], Train Loss: 0.0124, Val Loss: 1.1862, Val Accuracy: 76.90%\n",
      "Epoch [59/100], Train Loss: 0.0120, Val Loss: 1.1723, Val Accuracy: 79.85%\n",
      "Epoch [60/100], Train Loss: 0.0134, Val Loss: 1.1502, Val Accuracy: 79.62%\n",
      "Epoch [61/100], Train Loss: 0.0116, Val Loss: 1.1374, Val Accuracy: 76.67%\n",
      "Epoch [62/100], Train Loss: 0.0133, Val Loss: 1.1545, Val Accuracy: 80.96%\n",
      "Epoch [63/100], Train Loss: 0.0099, Val Loss: 1.1546, Val Accuracy: 79.98%\n",
      "Epoch [64/100], Train Loss: 0.0103, Val Loss: 1.3558, Val Accuracy: 81.16%\n",
      "Epoch [65/100], Train Loss: 0.0088, Val Loss: 1.2581, Val Accuracy: 78.45%\n",
      "Epoch [66/100], Train Loss: 0.0141, Val Loss: 1.2146, Val Accuracy: 80.84%\n",
      "Epoch [67/100], Train Loss: 0.0109, Val Loss: 1.3417, Val Accuracy: 80.09%\n",
      "Epoch [68/100], Train Loss: 0.0120, Val Loss: 1.2348, Val Accuracy: 79.76%\n",
      "Epoch [69/100], Train Loss: 0.0124, Val Loss: 1.1746, Val Accuracy: 79.61%\n",
      "Epoch [70/100], Train Loss: 0.0079, Val Loss: 1.2759, Val Accuracy: 80.32%\n",
      "Epoch [71/100], Train Loss: 0.0083, Val Loss: 1.5737, Val Accuracy: 80.80%\n",
      "Epoch [72/100], Train Loss: 0.0075, Val Loss: 1.3135, Val Accuracy: 80.77%\n",
      "Epoch [73/100], Train Loss: 0.0086, Val Loss: 1.3521, Val Accuracy: 78.82%\n",
      "Epoch [74/100], Train Loss: 0.0092, Val Loss: 1.3571, Val Accuracy: 80.49%\n",
      "Epoch [75/100], Train Loss: 0.0083, Val Loss: 1.2924, Val Accuracy: 78.85%\n",
      "Epoch [76/100], Train Loss: 0.0101, Val Loss: 1.2244, Val Accuracy: 78.74%\n",
      "Epoch [77/100], Train Loss: 0.0126, Val Loss: 1.2121, Val Accuracy: 76.31%\n",
      "Epoch [78/100], Train Loss: 0.0069, Val Loss: 1.2291, Val Accuracy: 78.45%\n",
      "Epoch [79/100], Train Loss: 0.0080, Val Loss: 1.1817, Val Accuracy: 77.18%\n",
      "Epoch [80/100], Train Loss: 0.0101, Val Loss: 1.4028, Val Accuracy: 80.52%\n",
      "Epoch [81/100], Train Loss: 0.0091, Val Loss: 1.1775, Val Accuracy: 80.18%\n",
      "Epoch [82/100], Train Loss: 0.0056, Val Loss: 1.5322, Val Accuracy: 80.96%\n",
      "Epoch [83/100], Train Loss: 0.0103, Val Loss: 1.3071, Val Accuracy: 80.13%\n",
      "Epoch [84/100], Train Loss: 0.0063, Val Loss: 1.4255, Val Accuracy: 79.66%\n",
      "Epoch [85/100], Train Loss: 0.0106, Val Loss: 1.5094, Val Accuracy: 78.20%\n",
      "Epoch [86/100], Train Loss: 0.0067, Val Loss: 1.5101, Val Accuracy: 79.48%\n",
      "Epoch [87/100], Train Loss: 0.0078, Val Loss: 1.4035, Val Accuracy: 80.45%\n",
      "Epoch [88/100], Train Loss: 0.0071, Val Loss: 1.4456, Val Accuracy: 76.51%\n",
      "Epoch [89/100], Train Loss: 0.0060, Val Loss: 1.3145, Val Accuracy: 78.42%\n",
      "Epoch [90/100], Train Loss: 0.0065, Val Loss: 1.5206, Val Accuracy: 81.31%\n",
      "Epoch [91/100], Train Loss: 0.0071, Val Loss: 1.4857, Val Accuracy: 80.50%\n",
      "Epoch [92/100], Train Loss: 0.0087, Val Loss: 1.2444, Val Accuracy: 80.73%\n",
      "Epoch [93/100], Train Loss: 0.0065, Val Loss: 1.3673, Val Accuracy: 80.36%\n",
      "Epoch [94/100], Train Loss: 0.0061, Val Loss: 1.6099, Val Accuracy: 80.44%\n",
      "Epoch [95/100], Train Loss: 0.0099, Val Loss: 1.4611, Val Accuracy: 80.45%\n",
      "Epoch [96/100], Train Loss: 0.0050, Val Loss: 1.4400, Val Accuracy: 80.89%\n",
      "Epoch [97/100], Train Loss: 0.0077, Val Loss: 1.5197, Val Accuracy: 80.21%\n",
      "Epoch [98/100], Train Loss: 0.0063, Val Loss: 1.4512, Val Accuracy: 79.45%\n",
      "Epoch [99/100], Train Loss: 0.0068, Val Loss: 1.3914, Val Accuracy: 79.73%\n",
      "Epoch [100/100], Train Loss: 0.0067, Val Loss: 1.4830, Val Accuracy: 80.08%\n",
      "\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "weight_for_apnea = Counter(y_train)[0]/Counter(y_train)[1] \n",
    "class_weights = torch.tensor([1.0, weight_for_apnea]).float().to(device)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights) # This loss function is perfect for multi-class classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# --- Training Loop ---\n",
    "print(\"Starting PyTorch model training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train() # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Iterate over batches of data from the DataLoader\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Move data to the selected device (MPS)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # 1. Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 3. Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 4. Backward pass (calculate gradients)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Update the model's weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # Disable gradient calculation for validation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nModel training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fce3e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating final model on the test set...\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Normal (0)       0.85      0.91      0.88      5941\n",
      "   Apnea (1)       0.53      0.39      0.45      1553\n",
      "\n",
      "    accuracy                           0.80      7494\n",
      "   macro avg       0.69      0.65      0.66      7494\n",
      "weighted avg       0.78      0.80      0.79      7494\n",
      "\n",
      "Confusion Matrix\n",
      "----------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Evaluating final model on the test set...\")\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# --- Classification Report and Confusion Matrix ---\n",
    "print('\\nClassification Report')\n",
    "print('---------------------')\n",
    "class_names = ['Normal (0)', 'Apnea (1)']\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print('----------------')\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm_norm, annot=True, fmt='.2%', cmap='Blues', \n",
    "    xticklabels=class_names, yticklabels=class_names\n",
    ")\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e29e980",
   "metadata": {},
   "source": [
    "*Leave one out Cross validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9903739",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fold_predictions = []\n",
    "all_fold_true_labels = []\n",
    "\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "n_folds = logo.get_n_splits(groups=groups)\n",
    "print(f\"Starting Leave-One-Night-Out cross-validation with {n_folds} folds...\")\n",
    "print(\"----------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "# --- 2. Loop through each fold ---\n",
    "for fold, (train_idx, test_idx) in enumerate(logo.split(X, y, groups)):\n",
    "    \n",
    "    # Identify which night is being left out for testing in this fold\n",
    "    test_night = np.unique(groups[test_idx])[0]\n",
    "    print(f\"--- FOLD {fold + 1}/{n_folds} ---\")\n",
    "    print(f\"Testing on Night: {test_night}\\n\")\n",
    "\n",
    "    # --- 3. Split the data for this fold ---\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # --- 4. Balance the TRAINING data for this fold ---\n",
    "    print(f\"  - Original training distribution for this fold: {Counter(y_train)}\")\n",
    "    nsamples, n_timesteps, n_features = X_train.shape\n",
    "    X_train_reshaped = X_train.reshape((nsamples, n_timesteps * n_features))\n",
    "    \n",
    "    smote = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_reshaped, y_train)\n",
    "    X_train_resampled = X_train_resampled.reshape(-1, n_timesteps, n_features)\n",
    "    print(f\"  - Resampled training distribution: {Counter(y_train_resampled)}\")\n",
    "\n",
    "    # --- 5. Create PyTorch DataLoaders for this fold ---\n",
    "    X_train_tensor = torch.from_numpy(X_train_resampled).float()\n",
    "    y_train_tensor = torch.from_numpy(y_train_resampled).long()\n",
    "    X_test_tensor = torch.from_numpy(X_test).float()\n",
    "    y_test_tensor = torch.from_numpy(y_test).long()\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # --- 6. Initialize and Train a NEW model for this fold ---\n",
    "    # It's crucial to re-initialize the model for each fold to avoid leakage.\n",
    "    model = OSA_CNN(n_features=n_features, n_outputs=2).to(device)\n",
    "    \n",
    "    # Define loss and optimizer (with class weights if you're using them)\n",
    "    criterion = nn.CrossEntropyLoss() # <-- Add your class weights here if needed\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    # (The full training loop from the previous step goes here)\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(f\"\\n  - Training complete for fold {fold + 1}.\")\n",
    "            \n",
    "    # --- 7. Evaluate the fold and store results ---\n",
    "    model.eval()\n",
    "    fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            fold_preds.extend(predicted.cpu().numpy())\n",
    "            \n",
    "    all_fold_predictions.extend(fold_preds)\n",
    "    all_fold_true_labels.extend(y_test)\n",
    "    print(f\"  - Evaluation complete for fold {fold + 1}.\\n\")\n",
    "\n",
    "\n",
    "# --- FINAL AGGREGATED EVALUATION (after all folds are complete) ---\n",
    "print(\"\\n====================================================\")\n",
    "print(\"Leave-One-Night-Out Cross-Validation Complete.\")\n",
    "print(\"Aggregated Results Across All Folds:\")\n",
    "print(\"====================================================\")\n",
    "\n",
    "# --- Final Classification Report ---\n",
    "print('\\nAggregated Classification Report')\n",
    "print('------------------------------')\n",
    "class_names = ['Normal (0)', 'Apnea (1)']\n",
    "print(classification_report(all_fold_true_labels, all_fold_predictions, target_names=class_names))\n",
    "\n",
    "# --- Final Confusion Matrix ---\n",
    "print('Aggregated Confusion Matrix')\n",
    "print('---------------------------')\n",
    "cm = confusion_matrix(all_fold_true_labels, all_fold_predictions)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm_norm, annot=True, fmt='.2%', cmap='Blues', \n",
    "    xticklabels=class_names, yticklabels=class_names\n",
    ")\n",
    "plt.title('Aggregated Normalized Confusion Matrix (LONO)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc7432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
