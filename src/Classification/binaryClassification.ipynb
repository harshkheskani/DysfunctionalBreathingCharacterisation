{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df119221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import pytz\n",
    "import os\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96248335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 event files. Processing each one...\n",
      "  - Processing session: 26-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 08-05-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 05-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 10-05-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 24-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 25-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 16-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 11-05-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "  - Processing session: 04-04-2025\n",
      "  - Preparing and merging engineered features using Unix time intervals...\n",
      "  - Applying precise interval-based labels...\n",
      "\n",
      "----------------------------------------------------\n",
      "Data loading with PRECISE interval labeling complete.\n",
      "Final DataFrame shape: (2139235, 30)\n",
      "Final class distribution in raw data: \n",
      "Label\n",
      "0    0.988052\n",
      "1    0.011948\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load in Data\n",
    "EVENTS_FOLDER = '../../data/bishkek_csr/03_train_ready/event_exports' \n",
    "RESPECK_FOLDER = '../../data/bishkek_csr/03_train_ready/respeck'\n",
    "NASAL_FOLDER = '../../data/bishkek_csr/03_train_ready/nasal_files'\n",
    "FEATURES_FOLDER = '../../data/bishkek_csr/03_train_ready/respeck_features'\n",
    "# --- Define relevant events ---\n",
    "APNEA_EVENT_LABELS = [\n",
    "    'Obstructive Apnea'\n",
    "]\n",
    "\n",
    "all_sessions_df_list = []\n",
    "event_files = glob.glob(os.path.join(EVENTS_FOLDER, '*_event_export.csv'))\n",
    "\n",
    "if not event_files:\n",
    "    raise FileNotFoundError(f\"No event files found in '{EVENTS_FOLDER}'.\")\n",
    "\n",
    "print(f\"Found {len(event_files)} event files. Processing each one...\")\n",
    "\n",
    "for event_file_path in event_files:\n",
    "    # --- 1. Setup paths and IDs ---\n",
    "    base_name = os.path.basename(event_file_path)\n",
    "    session_id = base_name.split('_event_export.csv')[0]\n",
    "    respeck_file_path = os.path.join(RESPECK_FOLDER, f'{session_id}_respeck.csv')\n",
    "    nasal_file_path = os.path.join(NASAL_FOLDER, f'{session_id}_nasal.csv')\n",
    "    feature_file_path = os.path.join(FEATURES_FOLDER, f'{session_id}_respeck_features.csv')\n",
    "    \n",
    "    if not all(os.path.exists(p) for p in [respeck_file_path, nasal_file_path, feature_file_path]):\n",
    "        print(f\"  - WARNING: Skipping session '{session_id}'. A corresponding file is missing.\")\n",
    "        continue\n",
    "    print(f\"  - Processing session: {session_id}\")\n",
    "    \n",
    "    # --- 2. Load all data sources ---\n",
    "    df_events = pd.read_csv(event_file_path, decimal=',')\n",
    "    df_nasal = pd.read_csv(nasal_file_path)\n",
    "    df_respeck = pd.read_csv(respeck_file_path)\n",
    "    df_features = pd.read_csv(feature_file_path)\n",
    "\n",
    "    # --- 3. Standardize timestamp columns and types ---\n",
    "    df_events.rename(columns={'UnixTimestamp': 'timestamp_unix'}, inplace=True)\n",
    "    df_nasal.rename(columns={'UnixTimestamp': 'timestamp_unix'}, inplace=True, errors='ignore')\n",
    "    df_respeck.rename(columns={'alignedTimestamp': 'timestamp_unix'}, inplace=True)\n",
    "    \n",
    "    df_features['timestamp_unix'] = pd.to_datetime(df_features['startTimestamp'], format=\"mixed\")\n",
    "    df_features['timestamp_unix'] = df_features['timestamp_unix'].astype('int64') // 10**6\n",
    "\n",
    "    df_features['timestamp_unix_end'] = pd.to_datetime(df_features['endTimestamp'], format=\"mixed\")\n",
    "    df_features['timestamp_unix_end'] = df_features['timestamp_unix_end'].astype('int64') // 10**6\n",
    "    \n",
    "    for df_ in [df_events, df_nasal, df_respeck]:\n",
    "        df_['timestamp_unix'] = pd.to_numeric(df_['timestamp_unix'], errors='coerce')\n",
    "        df_.dropna(subset=['timestamp_unix'], inplace=True)\n",
    "        df_['timestamp_unix'] = df_['timestamp_unix'].astype('int64')\n",
    "\n",
    "    # --- 4. Calculate the true overlapping time range ---\n",
    "    start_time = max(df_nasal['timestamp_unix'].min(), df_respeck['timestamp_unix'].min())\n",
    "    end_time = min(df_nasal['timestamp_unix'].max(), df_respeck['timestamp_unix'].max())\n",
    "    \n",
    "    # --- 5. Trim Respeck data to the overlapping time range ---\n",
    "    df_respeck = df_respeck[(df_respeck['timestamp_unix'] >= start_time) & (df_respeck['timestamp_unix'] <= end_time)].copy()\n",
    "\n",
    "    if df_respeck.empty:\n",
    "        print(f\"  - WARNING: Skipping session '{session_id}'. No Respeck data in the overlapping range.\")\n",
    "        continue\n",
    "\n",
    "    print(\"  - Preparing and merging engineered features using Unix time intervals...\")\n",
    "    df_respeck = df_respeck.sort_values('timestamp_unix')\n",
    "    df_features = df_features.sort_values('timestamp_unix')\n",
    "\n",
    "    # Use merge_asof to find the correct feature window for each respeck data point\n",
    "    df_session_merged = pd.merge_asof(\n",
    "        df_respeck,\n",
    "        df_features,\n",
    "        on='timestamp_unix',\n",
    "        direction='backward' # Finds the last feature window that started <= the respeck timestamp\n",
    "    )\n",
    "\n",
    "    cols_to_drop = ['Unnamed: 0','startTimestamp', 'endTimestamp', 'timestamp_unix_end']\n",
    "    df_session_merged.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "    if df_session_merged.empty:\n",
    "        print(f\"  - WARNING: Skipping session '{session_id}'. No merge matches found.\")\n",
    "        continue\n",
    "        \n",
    "    # --- 6. **NEW: Precise Interval-Based Labeling using Duration** ---\n",
    "    print(f\"  - Applying precise interval-based labels...\")\n",
    "    \n",
    "    # ** Step 6a: Initialize the label column in the respeck data with 0 (Normal)\n",
    "    df_session_merged['Label'] = 0\n",
    "    \n",
    "    # ** Step 6b: Calculate event end times using the 'Duration' column\n",
    "    # The 'Duration' column has commas, which we handled with `decimal=','` at load time.\n",
    "    # Convert duration from seconds to milliseconds to match the Unix timestamps.\n",
    "    df_events['Duration_ms'] = (df_events['Duration'] * 1000).astype('int64')\n",
    "    df_events['end_time_unix'] = df_events['timestamp_unix'] + df_events['Duration_ms']\n",
    "    \n",
    "    # ** Step 6c: Filter for only the apnea/hypopnea events we want to label as '1'\n",
    "    df_apnea_events = df_events[df_events['Event'].isin(APNEA_EVENT_LABELS)].copy()\n",
    "\n",
    "    # ** Step 6d: Efficiently label the respeck data using event intervals\n",
    "    # This is much faster than looping. It checks which respeck timestamps fall\n",
    "    # within any of the [start, end] intervals of the apnea events.\n",
    "    for index, event in df_apnea_events.iterrows():\n",
    "        start_event = event['timestamp_unix']\n",
    "        end_event = event['end_time_unix']\n",
    "        # Set the 'Label' to 1 for all respeck rows within this event's time interval\n",
    "        df_session_merged.loc[df_session_merged['timestamp_unix'].between(start_event, end_event), 'Label'] = 1\n",
    "\n",
    "    # --- 7. Finalize session data ---\n",
    "    df_session_merged['SessionID'] = session_id\n",
    "    all_sessions_df_list.append(df_session_merged)\n",
    "\n",
    "# --- Combine all nights and perform final processing ---\n",
    "if not all_sessions_df_list:\n",
    "    raise ValueError(\"Processing failed. No data was loaded.\")\n",
    "\n",
    "df = pd.concat(all_sessions_df_list, ignore_index=True)\n",
    "\n",
    "\n",
    "df.to_csv('test.csv')\n",
    "print(\"\\n----------------------------------------------------\")\n",
    "print(\"Data loading with PRECISE interval labeling complete.\")\n",
    "print(f\"Final DataFrame shape: {df.shape}\")\n",
    "print(f\"Final class distribution in raw data: \\n{df['Label'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8ea2c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp_unix', 'timestamp', 'interpolatedPhoneTimestamp',\n",
      "       'respeckTimestamp', 'sequenceNumber', 'x', 'y', 'z', 'breathingSignal',\n",
      "       'breathingRate', 'activityLevel', 'activityType', 'type', 'area',\n",
      "       'extremas', 'meanActivityLevel', 'modeActivityType',\n",
      "       'peakRespiratoryFlow', 'duration', 'BR_md', 'BR_mean', 'BR_std',\n",
      "       'AL_md', 'AL_mean', 'AL_std', 'RRV', 'RRV3MA', 'breath_regularity',\n",
      "       'Label', 'SessionID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Windowing: Creating the time-series segments.\n",
    "print(df.columns)\n",
    "\n",
    "SAMPLING_RATE_HZ = 12.5\n",
    "WINDOW_DURATION_SEC = 30\n",
    "WINDOW_SIZE = int(WINDOW_DURATION_SEC * SAMPLING_RATE_HZ)\n",
    "\n",
    "# Step size for sliding window. An 80% overlap is a good start.\n",
    "OVERLAP_PERCENTAGE = 0.80\n",
    "STEP_SIZE = int(WINDOW_SIZE * (1 - OVERLAP_PERCENTAGE))\n",
    "\n",
    "# === Data Parameters ===\n",
    "FEATURE_COLUMNS = [\n",
    "    'breathingSignal', \n",
    "    'activityLevel',\n",
    "    'RRV3MA',\n",
    "]\n",
    "LABEL_COLUMN = 'Label' \n",
    "SESSION_ID_COLUMN = 'SessionID'\n",
    "\n",
    "\n",
    "TEST_NIGHTS = 2\n",
    "TOTAL_NIGHTS = 9 \n",
    "TEST_SIZE = TEST_NIGHTS / TOTAL_NIGHTS\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4e53241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for and imputing missing values (NaNs)...\n",
      "\n",
      "Imputation complete. No NaNs remain in feature columns.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChecking for and imputing missing values (NaNs)...\")\n",
    "for col in df:\n",
    "    if col in df.columns:\n",
    "        nan_count = df[col].isnull().sum()\n",
    "        if nan_count > 0:\n",
    "            print(f\"  - Found {nan_count} NaNs in '{col}'. Applying forward-fill and backward-fill.\")\n",
    "            \n",
    "            # Step 1: Forward-fill handles all NaNs except leading ones.\n",
    "            df[col].ffill(inplace=True) \n",
    "            \n",
    "            # Step 2: Backward-fill handles any remaining NaNs at the beginning of the file.\n",
    "            df[col].bfill(inplace=True) \n",
    "\n",
    "# Add a final check to ensure everything is clean\n",
    "final_nan_count = df[FEATURE_COLUMNS].isnull().sum().sum()\n",
    "if final_nan_count > 0:\n",
    "    print(f\"\\nWARNING: {final_nan_count} NaNs still remain in feature columns after imputation. Please investigate.\")\n",
    "else:\n",
    "    print(\"\\nImputation complete. No NaNs remain in feature columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12ed1b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the windowing process...\n",
      "\n",
      "Data windowing complete.\n",
      "----------------------------------------------------\n",
      "Shape of X (features): (28868, 375, 3) -> (Num_Windows, Window_Size, Num_Features)\n",
      "Shape of y (labels):   (28868,)\n",
      "Shape of groups (IDs): (28868,)\n",
      "Final class distribution across all windows: Counter({np.int64(0): 27958, np.int64(1): 910}) (0=Normal, 1=Apnea)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "groups = [] \n",
    "\n",
    "print(\"Starting the windowing process...\")\n",
    "\n",
    "# --- 3. Loop through each session (night) to create windows ---\n",
    "# We group by SessionID to ensure windows do not cross over between nights.\n",
    "for session_id, session_df in df.groupby(SESSION_ID_COLUMN):\n",
    "    for i in range(0, len(session_df) - WINDOW_SIZE, STEP_SIZE):\n",
    "        \n",
    "        window_df = session_df.iloc[i : i + WINDOW_SIZE]\n",
    "        \n",
    "        features = window_df[FEATURE_COLUMNS].values\n",
    "        \n",
    "        # --- CORRECTED LABELING LOGIC ---\n",
    "        # The 'Label' column already contains 0s and 1s.\n",
    "        # If the sum of labels in the window is > 0, it means there's at least one '1' (Apnea).\n",
    "        if window_df[LABEL_COLUMN].sum() > 0:\n",
    "            label = 1 # Apnea\n",
    "        else:\n",
    "            label = 0 # Normal\n",
    "        # ------------------------------------\n",
    "            \n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "        groups.append(session_id)\n",
    "\n",
    "# --- 4. Convert the lists into efficient NumPy arrays ---\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "groups = np.asarray(groups)\n",
    "\n",
    "# --- 5. Print a summary of the results ---\n",
    "print(\"\\nData windowing complete.\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(f\"Shape of X (features): {X.shape} -> (Num_Windows, Window_Size, Num_Features)\")\n",
    "print(f\"Shape of y (labels):   {y.shape}\")\n",
    "print(f\"Shape of groups (IDs): {groups.shape}\")\n",
    "print(f\"Final class distribution across all windows: {Counter(y)} (0=Normal, 1=Apnea)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "475c0f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 unique sessions (nights) in the dataset: ['04-04-2025' '05-04-2025' '08-05-2025' '10-05-2025' '11-05-2025'\n",
      " '16-04-2025' '24-04-2025' '25-04-2025' '26-04-2025']\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "  - Sessions assigned to TRAINING set: ['16-04-2025' '04-04-2025' '26-04-2025' '08-05-2025' '11-05-2025'\n",
      " '10-05-2025' '24-04-2025']\n",
      "  - Sessions assigned to TESTING set:  ['25-04-2025' '05-04-2025']\n",
      "\n",
      "Train-test split complete.\n",
      "----------------------------------------------------\n",
      "Total windows in training set:   21374\n",
      "Total windows in testing set:    7494\n",
      "Shape of X_train:                (21374, 375, 3)\n",
      "Shape of X_test:                 (7494, 375, 3)\n",
      "Training set class distribution: Counter({np.int64(0): 20839, np.int64(1): 535}) (0=Normal, 1=Apnea)\n",
      "Testing set class distribution:  Counter({np.int64(0): 7119, np.int64(1): 375}) (0=Normal, 1=Apnea)\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset\n",
    "\n",
    "unique_session_ids = np.unique(groups)\n",
    "n_total_sessions = len(unique_session_ids)\n",
    "\n",
    "print(f\"Found {n_total_sessions} unique sessions (nights) in the dataset: {unique_session_ids}\")\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    unique_session_ids, \n",
    "    test_size=TEST_NIGHTS, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"\\nSplitting data into training and testing sets...\")\n",
    "print(f\"  - Sessions assigned to TRAINING set: {train_ids}\")\n",
    "print(f\"  - Sessions assigned to TESTING set:  {test_ids}\")\n",
    "\n",
    "train_mask = np.isin(groups, train_ids)\n",
    "test_mask = np.isin(groups, test_ids)\n",
    "\n",
    "# --- 4. Apply the masks to create the final data sets ---\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "# --- 5. Verify the results ---\n",
    "print(\"\\nTrain-test split complete.\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(f\"Total windows in training set:   {len(X_train)}\")\n",
    "print(f\"Total windows in testing set:    {len(X_test)}\")\n",
    "print(f\"Shape of X_train:                {X_train.shape}\")\n",
    "print(f\"Shape of X_test:                 {X_test.shape}\")\n",
    "print(f\"Training set class distribution: {Counter(y_train)} (0=Normal, 1=Apnea)\")\n",
    "print(f\"Testing set class distribution:  {Counter(y_test)} (0=Normal, 1=Apnea)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "768d4e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing the training data using SMOTE...\n",
      "  - Original training distribution: Counter({np.int64(0): 20839, np.int64(1): 535})\n",
      "  - Resampled training distribution: Counter({np.int64(0): 20839, np.int64(1): 20839})\n",
      "\n",
      "PyTorch DataLoaders created successfully.\n"
     ]
    }
   ],
   "source": [
    "nsamples, n_timesteps, n_features = X_train.shape\n",
    "X_train_reshaped = X_train.reshape((nsamples, n_timesteps * n_features))\n",
    "\n",
    "print(\"Balancing the training data using SMOTE...\")\n",
    "print(f\"  - Original training distribution: {Counter(y_train)}\")\n",
    "\n",
    "# --- 2. Initialize and apply SMOTE ---\n",
    "# `random_state` ensures that the synthetic samples are the same each time you run the code.\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_reshaped, y_train)\n",
    "\n",
    "print(f\"  - Resampled training distribution: {Counter(y_train_resampled)}\")\n",
    "\n",
    "# --- 3. Reshape the balanced training data back to its original 3D format ---\n",
    "# The model expects the data in the format (samples, timesteps, features).\n",
    "X_train_resampled = X_train_resampled.reshape((X_train_resampled.shape[0], n_timesteps, n_features))\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train_resampled).float()\n",
    "y_train_tensor = torch.from_numpy(y_train_resampled).long() # Use .long() for class indices\n",
    "\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders to handle batching and shuffling\n",
    "# BATCH_SIZE is from your configuration cell\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"\\nPyTorch DataLoaders created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be772b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984a4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model created and moved to MPS device.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OSA_CNN(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv1d(3, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv_block2): Sequential(\n",
       "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv_block3): Sequential(\n",
       "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=11968, out_features=100, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class OSA_CNN(nn.Module):\n",
    "    def __init__(self, n_features, n_outputs):\n",
    "        super(OSA_CNN, self).__init__()\n",
    "        \n",
    "        # NOTE: PyTorch's Conv1d expects input shape (batch, features, timesteps)\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=n_features, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        # The output size of the conv blocks needs to be calculated to define the linear layer\n",
    "        # For an input of 375, after one MaxPool1d(2), the size becomes floor(375/2) = 187\n",
    "        flattened_size = 64 * 187 # (out_channels * sequence_length_after_pooling)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened_size, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, n_outputs) # Output raw logits for CrossEntropyLoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # --- CRITICAL STEP: Reshape input for PyTorch Conv1d ---\n",
    "        # Input x has shape (batch, timesteps, features)\n",
    "        # We permute it to (batch, features, timesteps)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # ----------------------------------------------------\n",
    "        \n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        \n",
    "        # Now pass the features to the classifier\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "\n",
    "# Instantiate the model and move it to the MPS device\n",
    "n_outputs = 2 # (Normal, Apnea)\n",
    "model = OSA_CNN(n_features=n_features, n_outputs=n_outputs).to(device)\n",
    "\n",
    "print(\"PyTorch model created and moved to MPS device.\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12acdbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyTorch model training...\n",
      "Epoch [1/100], Train Loss: 0.1183, Val Loss: 2.8396, Val Accuracy: 5.70%\n",
      "Epoch [2/100], Train Loss: 0.1069, Val Loss: 2.5470, Val Accuracy: 9.05%\n",
      "Epoch [3/100], Train Loss: 0.0977, Val Loss: 2.5919, Val Accuracy: 9.74%\n",
      "Epoch [4/100], Train Loss: 0.0886, Val Loss: 2.3079, Val Accuracy: 15.40%\n",
      "Epoch [5/100], Train Loss: 0.0825, Val Loss: 1.8862, Val Accuracy: 24.09%\n",
      "Epoch [6/100], Train Loss: 0.0764, Val Loss: 2.2301, Val Accuracy: 22.97%\n",
      "Epoch [7/100], Train Loss: 0.0716, Val Loss: 2.0878, Val Accuracy: 23.34%\n",
      "Epoch [8/100], Train Loss: 0.0664, Val Loss: 1.9564, Val Accuracy: 26.67%\n",
      "Epoch [9/100], Train Loss: 0.0617, Val Loss: 1.7595, Val Accuracy: 39.51%\n",
      "Epoch [10/100], Train Loss: 0.0569, Val Loss: 1.9024, Val Accuracy: 35.70%\n",
      "Epoch [11/100], Train Loss: 0.0538, Val Loss: 1.5726, Val Accuracy: 50.60%\n",
      "Epoch [12/100], Train Loss: 0.0507, Val Loss: 2.5549, Val Accuracy: 28.85%\n",
      "Epoch [13/100], Train Loss: 0.0477, Val Loss: 1.8386, Val Accuracy: 49.20%\n",
      "Epoch [14/100], Train Loss: 0.0450, Val Loss: 2.0029, Val Accuracy: 49.49%\n",
      "Epoch [15/100], Train Loss: 0.0443, Val Loss: 1.6750, Val Accuracy: 57.81%\n",
      "Epoch [16/100], Train Loss: 0.0402, Val Loss: 1.8836, Val Accuracy: 55.79%\n",
      "Epoch [17/100], Train Loss: 0.0401, Val Loss: 2.2664, Val Accuracy: 45.32%\n",
      "Epoch [18/100], Train Loss: 0.0380, Val Loss: 2.0678, Val Accuracy: 50.21%\n",
      "Epoch [19/100], Train Loss: 0.0367, Val Loss: 2.0159, Val Accuracy: 54.82%\n",
      "Epoch [20/100], Train Loss: 0.0372, Val Loss: 1.7426, Val Accuracy: 54.32%\n",
      "Epoch [21/100], Train Loss: 0.0355, Val Loss: 2.0164, Val Accuracy: 56.81%\n",
      "Epoch [22/100], Train Loss: 0.0331, Val Loss: 1.8353, Val Accuracy: 61.84%\n",
      "Epoch [23/100], Train Loss: 0.0307, Val Loss: 1.8879, Val Accuracy: 65.75%\n",
      "Epoch [24/100], Train Loss: 0.0323, Val Loss: 1.9029, Val Accuracy: 65.31%\n",
      "Epoch [25/100], Train Loss: 0.0292, Val Loss: 1.9829, Val Accuracy: 71.64%\n",
      "Epoch [26/100], Train Loss: 0.0281, Val Loss: 1.9177, Val Accuracy: 69.50%\n",
      "Epoch [27/100], Train Loss: 0.0258, Val Loss: 1.9819, Val Accuracy: 69.24%\n",
      "Epoch [28/100], Train Loss: 0.0263, Val Loss: 1.9543, Val Accuracy: 67.77%\n",
      "Epoch [29/100], Train Loss: 0.0277, Val Loss: 1.9564, Val Accuracy: 72.10%\n",
      "Epoch [30/100], Train Loss: 0.0234, Val Loss: 2.1004, Val Accuracy: 76.07%\n",
      "Epoch [31/100], Train Loss: 0.0247, Val Loss: 2.0002, Val Accuracy: 72.68%\n",
      "Epoch [32/100], Train Loss: 0.0228, Val Loss: 2.2305, Val Accuracy: 71.00%\n",
      "Epoch [33/100], Train Loss: 0.0240, Val Loss: 2.1030, Val Accuracy: 75.21%\n",
      "Epoch [34/100], Train Loss: 0.0239, Val Loss: 2.1283, Val Accuracy: 74.98%\n",
      "Epoch [35/100], Train Loss: 0.0223, Val Loss: 2.0073, Val Accuracy: 75.77%\n",
      "Epoch [36/100], Train Loss: 0.0222, Val Loss: 2.0002, Val Accuracy: 71.36%\n",
      "Epoch [37/100], Train Loss: 0.0222, Val Loss: 2.0796, Val Accuracy: 76.53%\n",
      "Epoch [38/100], Train Loss: 0.0196, Val Loss: 2.1823, Val Accuracy: 78.21%\n",
      "Epoch [39/100], Train Loss: 0.0188, Val Loss: 2.1488, Val Accuracy: 72.94%\n",
      "Epoch [40/100], Train Loss: 0.0198, Val Loss: 2.2082, Val Accuracy: 70.40%\n",
      "Epoch [41/100], Train Loss: 0.0202, Val Loss: 2.3385, Val Accuracy: 66.49%\n",
      "Epoch [42/100], Train Loss: 0.0209, Val Loss: 2.2084, Val Accuracy: 71.83%\n",
      "Epoch [43/100], Train Loss: 0.0201, Val Loss: 2.3236, Val Accuracy: 80.38%\n",
      "Epoch [44/100], Train Loss: 0.0175, Val Loss: 2.3323, Val Accuracy: 75.53%\n",
      "Epoch [45/100], Train Loss: 0.0170, Val Loss: 2.3511, Val Accuracy: 75.54%\n",
      "Epoch [46/100], Train Loss: 0.0164, Val Loss: 2.2387, Val Accuracy: 74.61%\n",
      "Epoch [47/100], Train Loss: 0.0188, Val Loss: 2.3025, Val Accuracy: 77.17%\n",
      "Epoch [48/100], Train Loss: 0.0161, Val Loss: 2.3514, Val Accuracy: 78.57%\n",
      "Epoch [49/100], Train Loss: 0.0156, Val Loss: 2.5879, Val Accuracy: 80.92%\n",
      "Epoch [50/100], Train Loss: 0.0167, Val Loss: 2.2939, Val Accuracy: 78.44%\n",
      "Epoch [51/100], Train Loss: 0.0199, Val Loss: 2.5481, Val Accuracy: 75.05%\n",
      "Epoch [52/100], Train Loss: 0.0199, Val Loss: 2.4829, Val Accuracy: 80.13%\n",
      "Epoch [53/100], Train Loss: 0.0162, Val Loss: 2.6039, Val Accuracy: 81.60%\n",
      "Epoch [54/100], Train Loss: 0.0152, Val Loss: 2.5049, Val Accuracy: 77.12%\n",
      "Epoch [55/100], Train Loss: 0.0141, Val Loss: 2.5490, Val Accuracy: 78.62%\n",
      "Epoch [56/100], Train Loss: 0.0151, Val Loss: 2.6837, Val Accuracy: 80.26%\n",
      "Epoch [57/100], Train Loss: 0.0176, Val Loss: 2.3944, Val Accuracy: 80.60%\n",
      "Epoch [58/100], Train Loss: 0.0140, Val Loss: 2.7568, Val Accuracy: 81.04%\n",
      "Epoch [59/100], Train Loss: 0.0153, Val Loss: 2.5245, Val Accuracy: 75.98%\n",
      "Epoch [60/100], Train Loss: 0.0175, Val Loss: 2.4084, Val Accuracy: 79.84%\n",
      "Epoch [61/100], Train Loss: 0.0173, Val Loss: 2.4725, Val Accuracy: 82.39%\n",
      "Epoch [62/100], Train Loss: 0.0138, Val Loss: 2.6379, Val Accuracy: 85.00%\n",
      "Epoch [63/100], Train Loss: 0.0128, Val Loss: 3.0050, Val Accuracy: 78.97%\n",
      "Epoch [64/100], Train Loss: 0.0147, Val Loss: 2.8655, Val Accuracy: 78.60%\n",
      "Epoch [65/100], Train Loss: 0.0138, Val Loss: 2.8293, Val Accuracy: 74.18%\n",
      "Epoch [66/100], Train Loss: 0.0130, Val Loss: 2.9321, Val Accuracy: 78.53%\n",
      "Epoch [67/100], Train Loss: 0.0121, Val Loss: 3.1239, Val Accuracy: 78.65%\n",
      "Epoch [68/100], Train Loss: 0.0138, Val Loss: 2.5405, Val Accuracy: 82.47%\n",
      "Epoch [69/100], Train Loss: 0.0166, Val Loss: 2.5576, Val Accuracy: 73.15%\n",
      "Epoch [70/100], Train Loss: 0.0123, Val Loss: 2.9483, Val Accuracy: 81.31%\n",
      "Epoch [71/100], Train Loss: 0.0114, Val Loss: 3.0739, Val Accuracy: 82.29%\n",
      "Epoch [72/100], Train Loss: 0.0124, Val Loss: 2.7378, Val Accuracy: 80.32%\n",
      "Epoch [73/100], Train Loss: 0.0122, Val Loss: 2.8546, Val Accuracy: 66.80%\n",
      "Epoch [74/100], Train Loss: 0.0145, Val Loss: 2.8760, Val Accuracy: 77.25%\n",
      "Epoch [75/100], Train Loss: 0.0140, Val Loss: 2.8103, Val Accuracy: 79.56%\n",
      "Epoch [76/100], Train Loss: 0.0125, Val Loss: 2.7716, Val Accuracy: 78.77%\n",
      "Epoch [77/100], Train Loss: 0.0122, Val Loss: 2.9043, Val Accuracy: 79.22%\n",
      "Epoch [78/100], Train Loss: 0.0101, Val Loss: 2.8100, Val Accuracy: 84.64%\n",
      "Epoch [79/100], Train Loss: 0.0132, Val Loss: 2.5938, Val Accuracy: 75.37%\n",
      "Epoch [80/100], Train Loss: 0.0140, Val Loss: 2.8652, Val Accuracy: 84.53%\n",
      "Epoch [81/100], Train Loss: 0.0133, Val Loss: 2.7746, Val Accuracy: 80.72%\n",
      "Epoch [82/100], Train Loss: 0.0131, Val Loss: 2.6836, Val Accuracy: 79.98%\n",
      "Epoch [83/100], Train Loss: 0.0136, Val Loss: 2.6964, Val Accuracy: 73.33%\n",
      "Epoch [84/100], Train Loss: 0.0148, Val Loss: 2.7826, Val Accuracy: 81.18%\n",
      "Epoch [85/100], Train Loss: 0.0180, Val Loss: 2.6886, Val Accuracy: 78.86%\n",
      "Epoch [86/100], Train Loss: 0.0108, Val Loss: 2.6099, Val Accuracy: 82.35%\n",
      "Epoch [87/100], Train Loss: 0.0122, Val Loss: 2.8914, Val Accuracy: 84.92%\n",
      "Epoch [88/100], Train Loss: 0.0117, Val Loss: 3.1457, Val Accuracy: 84.09%\n",
      "Epoch [89/100], Train Loss: 0.0119, Val Loss: 2.6534, Val Accuracy: 76.19%\n",
      "Epoch [90/100], Train Loss: 0.0090, Val Loss: 2.9156, Val Accuracy: 82.09%\n",
      "Epoch [91/100], Train Loss: 0.0102, Val Loss: 2.6566, Val Accuracy: 79.58%\n",
      "Epoch [92/100], Train Loss: 0.0118, Val Loss: 2.7972, Val Accuracy: 86.27%\n",
      "Epoch [93/100], Train Loss: 0.0108, Val Loss: 2.4632, Val Accuracy: 84.48%\n",
      "Epoch [94/100], Train Loss: 0.0104, Val Loss: 2.7138, Val Accuracy: 82.08%\n",
      "Epoch [95/100], Train Loss: 0.0117, Val Loss: 3.0582, Val Accuracy: 86.67%\n",
      "Epoch [96/100], Train Loss: 0.0096, Val Loss: 2.9075, Val Accuracy: 82.20%\n",
      "Epoch [97/100], Train Loss: 0.0089, Val Loss: 3.0185, Val Accuracy: 78.25%\n",
      "Epoch [98/100], Train Loss: 0.0098, Val Loss: 3.0507, Val Accuracy: 81.83%\n",
      "Epoch [99/100], Train Loss: 0.0099, Val Loss: 2.7875, Val Accuracy: 81.33%\n",
      "Epoch [100/100], Train Loss: 0.0113, Val Loss: 2.9994, Val Accuracy: 83.37%\n",
      "\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "weight_for_apnea = Counter(y_train)[0]/Counter(y_train)[1] \n",
    "class_weights = torch.tensor([1.0, weight_for_apnea]).float().to(device)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights) # This loss function is perfect for multi-class classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# --- Training Loop ---\n",
    "print(\"Starting PyTorch model training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train() # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Iterate over batches of data from the DataLoader\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Move data to the selected device (MPS)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # 1. Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 3. Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 4. Backward pass (calculate gradients)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Update the model's weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # Disable gradient calculation for validation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nModel training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fce3e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating final model on the test set...\n",
      "\n",
      "Classification Report\n",
      "---------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Normal (0)       0.95      0.87      0.91      7119\n",
      "   Apnea (1)       0.08      0.22      0.12       375\n",
      "\n",
      "    accuracy                           0.83      7494\n",
      "   macro avg       0.52      0.54      0.51      7494\n",
      "weighted avg       0.91      0.83      0.87      7494\n",
      "\n",
      "Confusion Matrix\n",
      "----------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Evaluating final model on the test set...\")\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# --- Classification Report and Confusion Matrix ---\n",
    "print('\\nClassification Report')\n",
    "print('---------------------')\n",
    "class_names = ['Normal (0)', 'Apnea (1)']\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print('----------------')\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm_norm, annot=True, fmt='.2%', cmap='Blues', \n",
    "    xticklabels=class_names, yticklabels=class_names\n",
    ")\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e29e980",
   "metadata": {},
   "source": [
    "*Leave one out Cross validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9903739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Leave-One-Night-Out cross-validation with 9 folds...\n",
      "----------------------------------------------------\n",
      "\n",
      "--- FOLD 1/9 ---\n",
      "Testing on Night: 04-04-2025\n",
      "\n",
      "  - Original training distribution for this fold: Counter({np.int64(0): 24608, np.int64(1): 709})\n",
      "  - Resampled training distribution: Counter({np.int64(0): 24608, np.int64(1): 24608})\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     60\u001b[39m         loss = criterion(outputs, labels)\n\u001b[32m     61\u001b[39m         loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  - Training complete for fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# --- 7. Evaluate the fold and store results ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/optim/adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/optim/optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/optim/adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/optim/adam.py:439\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    436\u001b[39m     device_beta1 = beta1\n\u001b[32m    438\u001b[39m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m \u001b[43mexp_avg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_beta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[38;5;66;03m# Nested if is necessary to bypass jitscript rules\u001b[39;00m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m differentiable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(beta2, Tensor):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_fold_predictions = []\n",
    "all_fold_true_labels = []\n",
    "\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "n_folds = logo.get_n_splits(groups=groups)\n",
    "print(f\"Starting Leave-One-Night-Out cross-validation with {n_folds} folds...\")\n",
    "print(\"----------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "# --- 2. Loop through each fold ---\n",
    "for fold, (train_idx, test_idx) in enumerate(logo.split(X, y, groups)):\n",
    "    \n",
    "    # Identify which night is being left out for testing in this fold\n",
    "    test_night = np.unique(groups[test_idx])[0]\n",
    "    print(f\"--- FOLD {fold + 1}/{n_folds} ---\")\n",
    "    print(f\"Testing on Night: {test_night}\\n\")\n",
    "\n",
    "    # --- 3. Split the data for this fold ---\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # --- 4. Balance the TRAINING data for this fold ---\n",
    "    print(f\"  - Original training distribution for this fold: {Counter(y_train)}\")\n",
    "    nsamples, n_timesteps, n_features = X_train.shape\n",
    "    X_train_reshaped = X_train.reshape((nsamples, n_timesteps * n_features))\n",
    "    \n",
    "    smote = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_reshaped, y_train)\n",
    "    X_train_resampled = X_train_resampled.reshape(-1, n_timesteps, n_features)\n",
    "    print(f\"  - Resampled training distribution: {Counter(y_train_resampled)}\")\n",
    "\n",
    "    # --- 5. Create PyTorch DataLoaders for this fold ---\n",
    "    X_train_tensor = torch.from_numpy(X_train_resampled).float()\n",
    "    y_train_tensor = torch.from_numpy(y_train_resampled).long()\n",
    "    X_test_tensor = torch.from_numpy(X_test).float()\n",
    "    y_test_tensor = torch.from_numpy(y_test).long()\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # --- 6. Initialize and Train a NEW model for this fold ---\n",
    "    # It's crucial to re-initialize the model for each fold to avoid leakage.\n",
    "    model = OSA_CNN(n_features=n_features, n_outputs=2).to(device)\n",
    "    \n",
    "    # Define loss and optimizer (with class weights if you're using them)\n",
    "    criterion = nn.CrossEntropyLoss() # <-- Add your class weights here if needed\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    # (The full training loop from the previous step goes here)\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(f\"\\n  - Training complete for fold {fold + 1}.\")\n",
    "            \n",
    "    # --- 7. Evaluate the fold and store results ---\n",
    "    model.eval()\n",
    "    fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            fold_preds.extend(predicted.cpu().numpy())\n",
    "            \n",
    "    all_fold_predictions.extend(fold_preds)\n",
    "    all_fold_true_labels.extend(y_test)\n",
    "    print(f\"  - Evaluation complete for fold {fold + 1}.\\n\")\n",
    "\n",
    "\n",
    "# --- FINAL AGGREGATED EVALUATION (after all folds are complete) ---\n",
    "print(\"\\n====================================================\")\n",
    "print(\"Leave-One-Night-Out Cross-Validation Complete.\")\n",
    "print(\"Aggregated Results Across All Folds:\")\n",
    "print(\"====================================================\")\n",
    "\n",
    "# --- Final Classification Report ---\n",
    "print('\\nAggregated Classification Report')\n",
    "print('------------------------------')\n",
    "class_names = ['Normal (0)', 'Apnea (1)']\n",
    "print(classification_report(all_fold_true_labels, all_fold_predictions, target_names=class_names))\n",
    "\n",
    "# --- Final Confusion Matrix ---\n",
    "print('Aggregated Confusion Matrix')\n",
    "print('---------------------------')\n",
    "cm = confusion_matrix(all_fold_true_labels, all_fold_predictions)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm_norm, annot=True, fmt='.2%', cmap='Blues', \n",
    "    xticklabels=class_names, yticklabels=class_names\n",
    ")\n",
    "plt.title('Aggregated Normalized Confusion Matrix (LONO)')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc7432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
